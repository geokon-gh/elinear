<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2019-07-25 Thu 09:42 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Linear Systems in ELisp</title>
<meta name="generator" content="Org mode">
<meta name="author" content="George Kontsevich">
<meta name="description" content="Linear algebra system in ELisp from the basics"
>
<link rel="stylesheet" type="text/css" href="../web/worg.css" />
<link rel="shortcut icon" href="../web/panda.svg" type="image/x-icon">
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="../MathJax/MathJax.js?config=TeX-AMS_CHTML"></script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href=".."> UP </a>
 |
 <a accesskey="H" href=".."> HOME </a>
</div><div id="content">
<h1 class="title">Linear Systems in ELisp</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orge8b1b04">Preface</a></li>
<li><a href="#orgdee8e5e">Systems of linear equations</a>
<ul>
<li><a href="#org78f54b5">A farming problem</a></li>
</ul>
</li>
<li><a href="#org4e9001e">Matices as representations of linear systems</a>
<ul>
<li><a href="#org4c68d06">The Matrix in the computer</a>
<ul>
<li><a href="#orgdc9e981">Some helpers</a></li>
</ul>
</li>
<li><a href="#orga0fe53e">Transposition: Getting the other equivalent matrix</a></li>
</ul>
</li>
<li><a href="#orgbdd3004">Representing the whole system of equations</a>
<ul>
<li><a href="#orgdc3d451">Matrix Multiplication</a>
<ul>
<li><a href="#org9cb8a08">Inner Product</a></li>
<li><a href="#orgfe5adae">Submatrices</a></li>
<li><a href="#orgf9f94ae">Matrix Product</a></li>
<li><a href="#orgb75d167">Matrix Conformability</a></li>
<li><a href="#orgd36b53e">Addendum: Scalar Product</a></li>
</ul>
</li>
<li><a href="#org27ac654">A system of equations as matrix product</a>
<ul>
<li><a href="#org2726458">The mirror universe</a></li>
</ul>
</li>
<li><a href="#orgbba2eee">Chaining problems through matrix composition</a>
<ul>
<li><a href="#orgc6ad35e">Taxing our farmers</a></li>
<li><a href="#org3c413ab">EXAMPLE: Geometrical transformations</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgbb53953">Equivalent matrices</a>
<ul>
<li><a href="#org65f22c5">Identity Matrix</a></li>
<li><a href="#orge40909b">Unit Column/Rows</a></li>
<li><a href="#org64d6559">Addition</a></li>
<li><a href="#org2b9a465">Elementary Matrices</a>
<ul>
<li><a href="#orgf9fe47a">Type I - Row/Column Interchange</a></li>
<li><a href="#org52284e2">Type II - Row/Column Multiple</a></li>
<li><a href="#org42f005f">Type III - Row/Column Addition</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgd7008e5">The LU Decomposition</a>
<ul>
<li><a href="#org1e88c73">Gaussian elimination in matrix form</a>
<ul>
<li><a href="#orga4278ab">Elementary Lower Triangular Matrics</a></li>
<li><a href="#org0cc08e3">Building the <b>L</b> Matrix</a></li>
<li><a href="#orgdc22ae2">Partial Pivoting</a></li>
<li><a href="#org1b98301">Extracting the pivots</a></li>
</ul>
</li>
<li><a href="#org797eb20">Using the LU</a>
<ul>
<li><a href="#orgc7999dc">Solving for x in Ax=b</a></li>
<li><a href="#org3539968">The LDU Decomposition</a></li>
<li><a href="#orgc0742ff">The Cholesky Decomposition</a></li>
<li><a href="#org1cf4f2d">Solving for A<sup>-1</sup></a></li>
<li><a href="#org408683b">Least Squares</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgac4879f">The QR Decomposition</a>
<ul>
<li><a href="#org29c6c30">The Gram-Schmidt procedure</a>
<ul>
<li><a href="#org6856f62">The Base case</a></li>
<li><a href="#org5c210e7">Recursive Step</a></li>
</ul>
</li>
<li><a href="#org1199b59">Decomposing</a></li>
<li><a href="#orgceabc14">The Householder reduction</a>
<ul>
<li><a href="#orgef043d8">elementary reflector</a></li>
<li><a href="#orge3a18b0">elementary coordinate reflector</a></li>
<li><a href="#org17c2727">The QR decomposition - part 2</a></li>
</ul>
</li>
<li><a href="#org055e961">Givens reduction</a></li>
<li><a href="#orgd57424c">Least Squares again</a></li>
</ul>
</li>
<li><a href="#orgc118400"><span class="todo TODO">TODO</span> s</a></li>
<li><a href="#orge85c9c1">SRC<sub>Block</sub> template</a></li>
<li><a href="#org46e7558">End</a></li>
</ul>
</div>
</div>

<div id="outline-container-orge8b1b04" class="outline-2">
<h2 id="orge8b1b04">Preface</h2>
<div class="outline-text-2" id="text-orge8b1b04">
<p>
This text is primarily my personal notes on linear algebra as I go through <a href="https://www.matrixanalysis.com">Matrix Analysis &amp; Applied Linear Algebra</a>. At the same time this document is a literate program that can be executed in Emacs so the text will be slowly building up a linear algebra library of sorts. This will often not match the order things are presented in the book. There is no emphasis on performance - just on clarity, extensability and correctness when possible. This is purely (self)educational with my primary motivation being to help me better understand what I learn (through having to explain it) and to sanity check with actual programs. Things that are adequately explained in the book will not be repeated here.
</p>

<p>
This is my first program in Elisp, so if you see any issues, please leave a note in the <a href="https://github.com/geokon-gh/linearsystems/issues">issues</a> tab of <a href="https://github.com/geokon-gh/linearsystems/">the repository</a>. There you can also find the original org-mode file and the generated elisp files - both of which have additional unit-tests ommited from this webpage.
</p>

<p>
This is very much a work in progress and will change often&#x2026;
</p>
</div>
</div>

<div id="outline-container-orgdee8e5e" class="outline-2">
<h2 id="orgdee8e5e">Systems of linear equations</h2>
<div class="outline-text-2" id="text-orgdee8e5e">
<p>
The book's opening problem from ancient China of calculating the price of bushels of crop serves as a good example of a linear problem. I've simplified the problem a bit for clarity - but I will expand on it and refer back to it extensively:
</p>
</div>
<div id="outline-container-org78f54b5" class="outline-3">
<h3 id="org78f54b5">A farming problem</h3>
<div class="outline-text-3" id="text-org78f54b5">
<blockquote>
<p>
You have a 3 fruit farms in a region of ancient China. In a given year:
</p>

<p>
<b>Given 1:</b><br>
Farm 1 produces 3 tons of apples 2 ton of  oranges and 1 ton  of lemons<br>
Farm 2 produces 2 tons of apples 3 tons of oranges and 1 ton  of lemons<br>
Farm 3 produces 1 ton  of apples 2 tons of oranges and 3 tons of lemons<br>
</p>

<p>
<b>Given 2:</b><br>
Farm 1 sold its fruit for 39 yuan<br>
Farm 2 sold its fruit for 34 yuan<br>
Farm 3 sold its fruit for 26 yuan<br>
</p>

<p>
What is the price of the a ton of apples/oranges/lemons?
</p>
</blockquote>
<p>
This is a familiar problem that can be restated as a system of linear equations
</p>

\begin{equation}
\begin{split}
3x+2y+z = 39\\
2x+3y+z = 34\\
x+ 2y + 3z = 26
\end{split}
\end{equation}

<p>
Where <code>x</code>, <code>y</code> and <code>z</code> represent <code>apples</code> <code>oranges</code> and <code>lemons</code> respectively
</p>

<p>
We know how to solve this system by manipulating the equations, solving for a variable and then back-substituting the results.
</p>

<p>
It's not accident I split up the problem into two sets of <b>Givens</b>. It's important to note that the problem actually has two distinct and independent parts. There is the farm/crop <b>linear system</b> (<code>Given 1</code>), and then there is the <b>constraint</b> of the profits of each farm (<code>Given 2</code>)
</p>

<p>
We are looking for the input fruit-prices that will yield the given profits for each farm
</p>
</div>
</div>
</div>

<div id="outline-container-org4e9001e" class="outline-2">
<h2 id="org4e9001e">Matices as representations of linear systems</h2>
<div class="outline-text-2" id="text-org4e9001e">
<p>
The <b>linear system</b> can be represented with a matrix
</p>

\begin{bmatrix}
3 & 2 & 1\\
2 & 3 & 1\\
1 & 2 & 3\\
\end{bmatrix}

<p>
or flipped::
</p>

\begin{bmatrix}
3 & 2 & 1\\
2 & 3 & 2\\
1 & 1 & 3\\
\end{bmatrix}

<p>
We prefer the first representation, but both ways work as long as you remember what each row and column represents
</p>
</div>

<div id="outline-container-org4c68d06" class="outline-3">
<h3 id="org4c68d06">The Matrix in the computer</h3>
<div class="outline-text-3" id="text-org4c68d06">
<p>
Once we've chosen a layout the easiest way to store the matrix in the computer is to remember 3 values: <code>number-of-rows</code> <code>number-of-columns</code> <code>data</code>
</p>

<p>
The <code>data</code> value will be a long list of size <code>num-row * num-col</code> that contains all the values of the matrix; row after row. So given a list <code>data</code> and a pair of sizes we simply build the matrix into a list of these three values: 
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-from-data-list</span> (number-of-rows number-of-columns data-list<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Builds a matrix from a data list"</span>
  (list 
   number-of-rows 
   number-of-columns 
   data-list<span style="color: #999999;">))</span>
</pre>
</div>
</div>
<div id="outline-container-orgdc9e981" class="outline-4">
<h4 id="orgdc9e981">Some helpers</h4>
<div class="outline-text-4" id="text-orgdc9e981">
<p>
With a couple of helper function we can get back these 3 fields. This will improve the readability of the code as we go along
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-rows</span> (matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Get the number of rows"</span>
  (nth 0 matrix<span style="color: #999999;">))</span>
(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-columns</span> (matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Get the number of columns"</span>
  (nth 1 matrix<span style="color: #999999;">))</span>
(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-data</span> (matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Get the data list from the matrix"</span>
  (nth 2 matrix<span style="color: #999999;">))</span>
(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-get-value</span> (matrix row column<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Get the scalar value at position ROW COLUMN (ZERO indexed) from MATRIX"</span>
  (nth
   (+
    column
    (*
     row
     (matrix-columns matrix<span style="color: #999999;">)))</span>
    (matrix-data matrix<span style="color: #999999;">)))</span>
</pre>
</div>
<blockquote>
<p>
<code>nth</code> gets the nth element of the list
</p>
</blockquote>
<p>
For debugging and looking at results we also need to be able to print out the matrix for inspection
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-data-get-first-n-values</span> (data n<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Given a list of values, get the first n in a string"</span>
  (<span style="color: #0000FF;">if</span> (zerop n<span style="color: #999999;">)</span>
      <span style="color: #008000;">""</span> <span style="color: #8D8D84;">;</span><span style="color: #8D8D84; font-style: italic;">base case</span>
    (concat
     (number-to-string (car data<span style="color: #999999;">))</span>
     <span style="color: #008000;">" "</span>
     (matrix-data-get-first-n-values (cdr data) (1- n))))) <span style="color: #8D8D84;">;</span><span style="color: #8D8D84; font-style: italic;">iterative step</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-data-print</span> (number-of-rows number-of-columns data<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Print out the data list gives the dimension of the original matrix"</span>
  (<span style="color: #0000FF;">if</span> (zerop number-of-rows<span style="color: #999999;">)</span>
      <span style="color: #008000;">""</span> <span style="color: #8D8D84;">;</span><span style="color: #8D8D84; font-style: italic;">base case</span>
    (concat
     (matrix-data-get-first-n-values data number-of-columns<span style="color: #999999;">)</span>
     <span style="color: #008000;">"\n"</span>
     (matrix-data-print <span style="color: #8D8D84;">;</span><span style="color: #8D8D84; font-style: italic;">iterative step</span>
      (1- number-of-rows<span style="color: #999999;">)</span>
      number-of-columns
      (nthcdr number-of-columns data <span style="color: #999999;">)))))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-print</span> (matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Print out the matrix"</span>
  (concat <span style="color: #008000;">"\n"</span> (matrix-data-print
                (matrix-rows matrix<span style="color: #999999;">)</span>
                (matrix-columns matrix<span style="color: #999999;">)</span>
                (matrix-data matrix<span style="color: #999999;">))))</span>
<span style="color: #8D8D84;">; </span><span style="color: #8D8D84; font-style: italic;">ex:  (message (matrix-print (matrix-from-data-list 2 2 '(1 2 3 4))))</span>
</pre>
</div>
<blockquote>
<p>
<code>zerop</code> tests if the value is zero
</p>
</blockquote>
<blockquote>
<p>
<code>()</code> with a quote is the <i>empty-list</i> 
</p>
</blockquote>
<blockquote>
<p>
<code>cons</code> attaches the first argument to the second argument (which is normally a list)
</p>
</blockquote>
<blockquote>
<p>
<code>cdr</code> returns the list without the first element
</p>
</blockquote>
</div>
</div>
</div>
<div id="outline-container-orga0fe53e" class="outline-3">
<h3 id="orga0fe53e">Transposition: Getting the other equivalent matrix</h3>
<div class="outline-text-3" id="text-orga0fe53e">
<p>
Since we have two equivalent matrices that represent our linear system we need a mechanism to go from one to the other. This method is the matrix transpose which flips the matrix along the diagonal. The text goes into depth on the properties of the matrix transpose, but in short, as long as you take the transpose of both sides of your equations equivalances will be preserved.
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-transpose</span> (matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Get the transpose of a matrix"</span>
  (<span style="color: #0000FF;">if</span> (equal (matrix-columns matrix) 1<span style="color: #999999;">)</span>
    (matrix-from-data-list
     1
     (matrix-rows matrix<span style="color: #999999;">)</span>
     (matrix-data matrix<span style="color: #999999;">))</span>
    (matrix-append
     (matrix-from-data-list
      1
      (matrix-rows matrix<span style="color: #999999;">)</span>
      (matrix-data (matrix-get-column matrix 0<span style="color: #999999;">)))</span>
     (matrix-transpose
      (matrix-submatrix
       matrix
       0
       1
       (matrix-rows matrix<span style="color: #999999;">)</span>
       (matrix-columns matrix<span style="color: #999999;">))))))</span>
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orgbdd3004" class="outline-2">
<h2 id="orgbdd3004">Representing the whole system of equations</h2>
<div class="outline-text-2" id="text-orgbdd3004">
<p>
Now that we can represent the fruit/profits system we want a mechanism to represent the whole system of equations so that given a constraint, we can solve for a solution.
</p>
</div>
<div id="outline-container-orgdc3d451" class="outline-3">
<h3 id="orgdc3d451">Matrix Multiplication</h3>
<div class="outline-text-3" id="text-orgdc3d451">
<p>
This is done notationally with matrix multiplication. The notation allows us to keep the two <b>Givens</b> separated and allows us to visually chain linear systems together. As a shorthand, we write the product of two matrices <code>A</code> and <code>B</code> as <code>AB = C</code>, with the order of <code>A</code> and <code>B</code> being important. For every value (at a given row and column position) in the resulting matrix <code>C</code> we take the equivalent row in <code>A</code> and multiply it by its equivalent column in <code>B</code>. From this we can conclude that <code>C</code> will have as many rows as <code>A</code> and as many column as <code>B</code>
</p>

<p>
Multiplying a row times a column is called an <code>inner product</code>
</p>
</div>

<div id="outline-container-org9cb8a08" class="outline-4">
<h4 id="org9cb8a08">Inner Product</h4>
<div class="outline-text-4" id="text-org9cb8a08">
<p>
The <code>inner-product</code> is defined as the sum of the product of every pair of equivalent elements in the two vectors. The sum will naturally return one scalar value. This operation only makes sense if both the row and column have the same number of values.
</p>

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-inner-product-data</span> (row-data column-data<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Multiply a row times a column and returns a scalar. If they're empty you will get zero"</span>
  (reduce
   '+
   (for-each-pair
    row-data
    column-data
   '*<span style="color: #999999;">)))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-inner-product</span> (row column<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Multiply a row times a column and returns a scalar. If they're empty you will get zero"</span>
  (matrix-inner-product-data 
   (matrix-data row<span style="color: #999999;">)</span>
   (matrix-data column<span style="color: #999999;">)))</span>
</pre>
</div>
<blockquote>
<p>
<code>reduce</code> works down the list elements-by-element applying the operator on each cumulative result
</p>
</blockquote>
</div>
</div>

<div id="outline-container-orgfe5adae" class="outline-4">
<h4 id="orgfe5adae">Submatrices</h4>
<div class="outline-text-4" id="text-orgfe5adae">
<p>
To get rows and columns (and other submatrices) we need a few more helper functions
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-extract-subrow</span> (matrix row start-column end-column<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Get part of a row of a matrix and generate a row matrix from it. START-COLUMN is inclusive,  END-COLUMN is exclusive"</span>
  (<span style="color: #0000FF;">let</span>
      ((number-of-columns-on-input (matrix-columns matrix<span style="color: #999999;">))</span>
       (number-of-columns-on-output (-
                                     end-column 
                                     start-column<span style="color: #999999;">)))</span>
    (matrix-from-data-list
     1
     number-of-columns-on-output
     (subseq
      (matrix-data matrix<span style="color: #999999;">)</span>
      (+ (* row number-of-columns-on-input) start-column<span style="color: #999999;">)</span>
      (+ (* row number-of-columns-on-input) end-column<span style="color: #999999;">)))))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-append</span> (matrix1 matrix2<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Append one matrix (set of linear equations) to another"</span>
  (<span style="color: #0000FF;">if</span> (null matrix2<span style="color: #999999;">)</span>
      matrix1
    (matrix-from-data-list
     (+
      (matrix-rows matrix2<span style="color: #999999;">)</span>
      (matrix-rows matrix1<span style="color: #999999;">))</span>
     (matrix-columns matrix1<span style="color: #999999;">)</span>
     (append
      (matrix-data matrix1<span style="color: #999999;">)</span>
      (matrix-data matrix2<span style="color: #999999;">)))))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-submatrix</span> (matrix start-row start-column end-row end-column<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Get a submatrix. start-row/column are inclusive. end-row/column are exclusive"</span>
  (<span style="color: #0000FF;">if</span> (equal start-row end-row<span style="color: #999999;">)</span>
      '(<span style="color: #999999;">)</span>
    (matrix-append
     (matrix-extract-subrow matrix start-row start-column end-column<span style="color: #999999;">)</span>
     (matrix-submatrix
      matrix
      (1+ start-row<span style="color: #999999;">)</span>
      start-column
      end-row
      end-column<span style="color: #999999;">))))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-get-row</span> (matrix row<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Get a row from a matrix. Index starts are ZERO"</span>
  (matrix-extract-subrow
   matrix
   row
   0
   (matrix-columns matrix<span style="color: #999999;">)))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-get-column</span> (matrix column<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Get a column from a matrix. Index starts are ZERO"</span>
  (matrix-submatrix
   matrix
   0
   column
   (nth 0 matrix<span style="color: #999999;">)</span>
   (1+ column<span style="color: #999999;">)))</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orgf9f94ae" class="outline-4">
<h4 id="orgf9f94ae">Matrix Product</h4>
<div class="outline-text-4" id="text-orgf9f94ae">
<p>
Now we have all the tools we need to write down the algorithm for calculating the matrix product. First we write a function to calculate the product for one value at a given position
</p>

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-product-one-value</span> (matrix1 matrix2 row column<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Calculate one value in the resulting matrix of the product of two matrices"</span>
  (matrix-inner-product
   (matrix-get-row matrix1 row <span style="color: #999999;">)</span>
   (matrix-get-column matrix2 column<span style="color: #999999;">)))</span>
</pre>
</div>
<p>
And then we recursively apply it to construct the resulting matrix
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-product</span> (matrix1 matrix2<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Multiply two matrices"</span>

  (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-product-rec</span> (matrix1 matrix2 row column<span style="color: #999999;">)</span>
    <span style="color: #036A07;">"A recursive helper function that builds the matrix multiplication's data vector"</span>
    (<span style="color: #0000FF;">if</span> (equal (matrix-rows matrix1) row<span style="color: #999999;">)</span>
        '(<span style="color: #999999;">)</span>
      (<span style="color: #0000FF;">if</span> (equal (matrix-columns matrix2) column<span style="color: #999999;">)</span>
          (matrix-product-rec
           matrix1
           matrix2
           (1+ row<span style="color: #999999;">)</span>
           0<span style="color: #999999;">)</span>
        (cons
         (matrix-product-one-value
          matrix1
          matrix2
          row column<span style="color: #999999;">)</span>
         (matrix-product-rec
          matrix1
          matrix2
          row
          (1+ column<span style="color: #999999;">))))))</span>

  (matrix-from-data-list
   (matrix-rows matrix1<span style="color: #999999;">)</span>
   (matrix-columns matrix2<span style="color: #999999;">)</span>
   (matrix-product-rec
    matrix1
    matrix2
    0
    0<span style="color: #999999;">)))</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orgb75d167" class="outline-4">
<h4 id="orgb75d167">Matrix Conformability</h4>
<div class="outline-text-4" id="text-orgb75d167">
<p>
You will notice that the algorithm won't make sense if the number of columns of <code>A</code> doesn't match the number of rows of <code>B</code>. When the values match the matrices are called <b>conformable</b>. When they <i>don't</i> match you will see that inner product isn't defined and therefore neither is the product.
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-conformable?</span> (matrix1 matrix2<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Check that two matrices can be multiplied"</span>
  (equal
   (matrix-columns matrix1<span style="color: #999999;">)</span>
   (matrix-rows matrix2<span style="color: #999999;">)))</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-orgd36b53e" class="outline-4">
<h4 id="orgd36b53e">Addendum: Scalar Product</h4>
<div class="outline-text-4" id="text-orgd36b53e">
<p>
An additional form of matrix multiplication is between a matrix and a scalar. Here we simply multiply each element of the matrix times the scalar to construct the resulting matrix. The order of multiplication is not important -&gt; <b>&alpha;A=A&alpha;</b>
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-scalar-product</span> (matrix scalar<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Multiple the matrix by a scalar. ie. multiply each value by the scalar"</span>
  (matrix-from-data-list
   (matrix-rows matrix<span style="color: #999999;">)</span>
   (matrix-columns matrix<span style="color: #999999;">)</span>
   (mapcar
   (<span style="color: #0000FF;">lambda</span> (x) 
     (* scalar x<span style="color: #999999;">))</span>
   (matrix-data matrix<span style="color: #999999;">))))</span>
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org27ac654" class="outline-3">
<h3 id="org27ac654">A system of equations as matrix product</h3>
<div class="outline-text-3" id="text-org27ac654">
<p>
Now that we have all our tools we can write down a matrix product that will mimic our system of equation.
</p>

\begin{equation}
\begin{bmatrix}
3 & 2 & 1\\
2 & 3 & 1\\
1 & 2 & 3\\
\end{bmatrix}
\begin{bmatrix}
x\\
y\\
z\\
\end{bmatrix}
=
\begin{bmatrix}
39\\
34\\
26\\
\end{bmatrix}
\end{equation}

<p>
Going through our algorithm manually we see that the resulting matrix is:
</p>

\begin{equation}
\begin{bmatrix}
3x + 2y + z\\
2x + 3y + z\\
x + 2y + 3z\\
\end{bmatrix}
=
\begin{bmatrix}
39\\
34\\
26\\
\end{bmatrix}
\end{equation}
</div>

<div id="outline-container-org2726458" class="outline-4">
<h4 id="org2726458">The mirror universe</h4>
<div class="outline-text-4" id="text-org2726458">
<p>
Now I said that flipped matrix was also a valid representation. We can confirm this by taking the transpose of both sides 
</p>


\begin{equation}
\begin{bmatrix}
x & y & z\\
\end{bmatrix}
\begin{bmatrix}
3 & 2 & 1\\
2 & 3 & 2\\
1 & 1 & 3\\
\end{bmatrix}
=
\begin{bmatrix}
39 & 34 & 26\\
\end{bmatrix}
\end{equation}


<p>
It yields another matrix product that mimics the equations, however you'll see in the textbook that we always prefer the first notation.
</p>
</div>
</div>
</div>

<div id="outline-container-orgbba2eee" class="outline-3">
<h3 id="orgbba2eee">Chaining problems through matrix composition</h3>
<div class="outline-text-3" id="text-orgbba2eee">
<p>
The real power of matrix multiplication is in its ability to chain systems together through <b>linear composition</b>
</p>

<p>
If we are given a new problem that take the output of our first system and produces a new output - composition gives us a mechanism to combine the systems into one.
</p>
</div>

<div id="outline-container-orgc6ad35e" class="outline-4">
<h4 id="orgc6ad35e">Taxing our farmers</h4>
<div class="outline-text-4" id="text-orgc6ad35e">
<p>
Say the imperial palace has a system for collecting taxes
</p>
<blockquote>
<p>
<b>Given</b>:<br>
The farms have to pay a percentage of their income to different regional governements. The breakdown is as follows:<br>
The town taxes Farm 1 at 5%, Farm 2 at 3%, Farm 3 at 7%<br>
The province taxes all Farm 1 at 2% Farm 2 at 4%, Farm 3 at 2%<br>
The palace taxes all farms at 7%
</p>
</blockquote>
<p>
Now, given the income of each farm <b>i</b> we can build a new matrix <b>B</b> and calculate the tax revenue of each government - <b>t</b>.<br>
</p>

\begin{equation}
Bi=t
\end{equation}

<p>
From the previous problem we know that the income of each farm was already a system of equation with the price of fruit as input <b>f</b><br>
</p>

\begin{equation}
Af=i
\end{equation}

<p>
So we just plug one into the other and get<br>
</p>
\begin{equation}
B(Af)=t
\end{equation}

<p>
and compose a new equation that given the price of fruit gives us the regional tax revenue. By carrying out the product we can generate one linear system<br>
</p>

\begin{equation}
(BA)f=t\\
\end{equation} 
<p>
Where if <b>BA=C</b> the final composed system is:
</p>
\begin{equation}
Cf=t
\end{equation} 
<p>
Note that the rows of <b>BA</b> are the combination of the rows of <b>A</b> and the columns of <b>BA</b> are the combination of the columns of <b>B</b> - at the same time! (see page 98)
</p>
</div>
</div>
<div id="outline-container-org3c413ab" class="outline-4">
<h4 id="org3c413ab">EXAMPLE: Geometrical transformations</h4>
<div class="outline-text-4" id="text-org3c413ab">
<p>
A very simple example are the linear systems that takes coordinates <i>x y</i> and do transformations on them
</p>

<p>
<b>Rotation</b>
</p>
\begin{equation}
\begin{bmatrix}
\cos \theta & -\sin \theta \\
\sin \theta & \cos \theta \\
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
\end{bmatrix}
=
\begin{bmatrix}
x_{rotated}\\
y_{rotated}\\
\end{bmatrix}
\end{equation}

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-rotate-2D</span> (radians<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Generate a matrix that will rotates a [x y] column vector by RADIANS"</span>
  (matrix-from-data-list
   2
   2
   (list
     (cos radians<span style="color: #999999;">)</span>
     (- (sin radians<span style="color: #999999;">))</span>
     (sin radians<span style="color: #999999;">)</span>
     (cos radians<span style="color: #999999;">))))</span>
</pre>
</div>
<p>
<b>Reflection about X-Axis</b>
</p>
\begin{equation}
\begin{bmatrix}
1 & 0 \\
0 & -1\\
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
\end{bmatrix}
=
\begin{bmatrix}
x_{reflected}\\
y_{reflected}\\
\end{bmatrix}
\end{equation}

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-reflect-around-x-2D</span> (<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Generate a matrix that will reflect a [x y] column vector around the x axis"</span>
  (matrix-from-data-list
   2
   2
   '(1 0 0 -1<span style="color: #999999;">)))</span>
</pre>
</div>
<p>
<b>Projection on line</b>
</p>
\begin{equation}
\begin{bmatrix}
1/2 & 1/2 \\
1/2 & 1/2\\
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
\end{bmatrix}
=
\begin{bmatrix}
x_{projected}\\
y_{projected}\\
\end{bmatrix}
\end{equation}

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-project-on-x=y-diagonal-2D</span> (<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Generate a matrix that projects a point ([x y] column vector) onto a line (defined w/ a unit-vector)"</span>
  (matrix-from-data-list
   2
   2
   '(0.5 0.5 0.5 0.5<span style="color: #999999;">)))</span>
</pre>
</div>
<p>
So given a point <i>[x y]</i> (represented by the column vector <b>v</b>) we can use these 3 transformation matrices to move it around our 2D space. We simple write a chain of transformations <b>T</b> and multiply them times the given vector <b>T<sub>1</sub>T<sub>2</sub>T<sub>3</sub>v=v<sub>new</sub></b>. These transformation matrices can then be multiplied together into one that will carry out the transformation in one matrix product. <b>T<sub>1</sub>T<sub>2</sub>T<sub>3</sub>=T<sub>total</sub></b> =&gt; <b>T<sub>total</sub>v=v<sub>new</sub></b> 
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgbb53953" class="outline-2">
<h2 id="orgbb53953">Equivalent matrices</h2>
<div class="outline-text-2" id="text-orgbb53953">
<p>
Now thanks to matrix multiplication we can represent linear systems and we can chain them together. The next step is extending multiplication to represent general manipulations of matrices.
</p>
</div>

<div id="outline-container-org65f22c5" class="outline-3">
<h3 id="org65f22c5">Identity Matrix</h3>
<div class="outline-text-3" id="text-org65f22c5">
<p>
For any matrix <b>A</b>, the identity matrix <b>I</b> is such that <b>A*I</b> = <b>A</b> = <b>I*A</b>. Given the dimensions, <b>I</b> has to be a square matrix. It will have <b>1</b>'s on the diagonal (ie. where <code>row==column</code>) and zeroes everywhere else. We build it recursively:
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-identity</span> (rank<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Build an identity matrix of the given size/rank"</span>

  (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-build-identity-rec</span> (rank row column<span style="color: #999999;">)</span>
    <span style="color: #036A07;">"Helper function that build the data vector of the identity matrix"</span>
    (<span style="color: #0000FF;">if</span> (equal column rank) <span style="color: #8D8D84;">; </span><span style="color: #8D8D84; font-style: italic;">time to build next row</span>
        (<span style="color: #0000FF;">if</span> (equal row (1- rank<span style="color: #999999;">))</span>
            '() <span style="color: #8D8D84;">; </span><span style="color: #8D8D84; font-style: italic;">we're done</span>
          (matrix-build-identity-rec
           rank
           (1+ row<span style="color: #999999;">)</span>
           0<span style="color: #999999;">))</span>
      (<span style="color: #0000FF;">if</span> (equal row column<span style="color: #999999;">)</span>
          (cons
           1.0
           (matrix-build-identity-rec
            rank
            row
            (1+ column<span style="color: #999999;">)))</span>
        (cons
         0.0
         (matrix-build-identity-rec
          rank
          row
          (1+ column<span style="color: #999999;">))))))</span>

  (matrix-from-data-list rank rank (matrix-build-identity-rec rank 0 0 <span style="color: #999999;">)))</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orge40909b" class="outline-3">
<h3 id="orge40909b">Unit Column/Rows</h3>
<div class="outline-text-3" id="text-orge40909b">
<p>
Each column of the <b>identity matrix</b> is a unit column (denoted as <b>e<sub><i>j</i></sub></b>). It contains a <b>1</b> in a given postion (here: <i>j</i>) and <b>0s</b> everwhere else. Its transpose is naturally called the <b>unit row</b><br>
<b>Ae<sub><i>j</i></sub></b> = the <i>j</i> column of A<br>
<b>e<sub><i>i</i></sub><sup>T</sup>A</b> = the <i>i</i> row of A<br>
<b>e<sub><i>i</i></sub><sup>T</sup>Ae<sub><i>j</i></sub></b> = gets the [ <i>i</i>, <i>j</i> ] element in A
</p>

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-unit-rowcol-data</span> (index size<span style="color: #999999;">)</span>
<span style="color: #036A07;">"Create a data-list for a matrix row/column. INDEX (starts at ZERO) matches the row or column where you want a 1. SIZE is the overall size of the vector"</span>
(<span style="color: #0000FF;">if</span> (zerop size<span style="color: #999999;">)</span>
    '(<span style="color: #999999;">)</span>
  (<span style="color: #0000FF;">if</span> (zerop index<span style="color: #999999;">)</span>
      (cons
       1.0
       (matrix-unit-rowcol-data
        (1- index<span style="color: #999999;">)</span>
        (1- size<span style="color: #999999;">)))</span>
    (cons
     0.0
     (matrix-unit-rowcol-data
      (1- index<span style="color: #999999;">)</span>
      (1- size<span style="color: #999999;">))))))</span>
(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-unit-column</span> (row size<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Build a unit column. ROW is where you want the 1 to be placed (ZERO indexed). SIZE is the overall length"</span>
      (matrix-from-data-list
       size
       1
       (matrix-unit-rowcol-data
        row
        size<span style="color: #999999;">)))</span>
(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-unit-row</span> (column size<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Build a unit column. COLUMN is where you want the 1 to be placed (ZERO indexed). SIZE is the overall length"</span>
      (matrix-from-data-list
       1
       size
       (matrix-unit-rowcol-data
        column
        size<span style="color: #999999;">)))</span>

</pre>
</div>
<blockquote>
<p>
Here I'm just trying out a new notation. With <code>letrec</code> we can hide the recursive helper function inside the function that uses it.
</p>
</blockquote>
</div>
</div>

<div id="outline-container-org64d6559" class="outline-3">
<h3 id="org64d6559">Addition</h3>
<div class="outline-text-3" id="text-org64d6559">
<p>
As a tool in building new matrices, we need a way to easily add two matrices, ie. add their values one to one. Matrices that are added need to have the same size.
</p>

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-equal-size-p</span> (matrix1 matrix2<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Check if 2 matrices are the same size"</span>
  (<span style="color: #0000FF;">and</span>
   (equal
    (matrix-rows matrix1<span style="color: #999999;">)</span>
    (matrix-rows matrix2<span style="color: #999999;">))</span>
   (equal
    (matrix-columns matrix1<span style="color: #999999;">)</span>
    (matrix-columns matrix2<span style="color: #999999;">))))</span>
(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">for-each-pair</span> (list1 list2 operator<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Go through 2 lists applying an operator on each pair of elements"</span>
  (<span style="color: #0000FF;">if</span> (null list1<span style="color: #999999;">)</span>
      '(<span style="color: #999999;">)</span>
    (cons
     (funcall operator (car list1) (car list2<span style="color: #999999;">))</span>
     (for-each-pair (cdr list1) (cdr list2) operator<span style="color: #999999;">))))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-add</span> (matrix1 matrix2<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Add to matrices together"</span>
  (<span style="color: #0000FF;">if</span> (matrix-equal-size-p matrix1 matrix2<span style="color: #999999;">)</span>
      (matrix-from-data-list
       (matrix-rows matrix1<span style="color: #999999;">)</span>
       (matrix-columns matrix1<span style="color: #999999;">)</span>
       (for-each-pair
        (matrix-data matrix1<span style="color: #999999;">)</span>
        (matrix-data matrix2<span style="color: #999999;">)</span>
        '+<span style="color: #999999;">))))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-subtract</span> (matrix1 matrix2<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Subtract MATRIX2 from MATRIX1"</span>
  (<span style="color: #0000FF;">if</span> (matrix-equal-size-p matrix1 matrix2<span style="color: #999999;">)</span>
      (matrix-from-data-list
       (matrix-rows matrix1<span style="color: #999999;">)</span>
       (matrix-columns matrix1<span style="color: #999999;">)</span>
       (for-each-pair
        (matrix-data matrix1<span style="color: #999999;">)</span>
        (matrix-data matrix2<span style="color: #999999;">)</span>
        '-<span style="color: #999999;">))))</span>
</pre>
</div>
<blockquote>
<p>
<code>funcall</code> applied the first arugment (a function) with the remaining items in the list as arguments
</p>
</blockquote>
</div>
</div>
<div id="outline-container-org2b9a465" class="outline-3">
<h3 id="org2b9a465">Elementary Matrices</h3>
<div class="outline-text-3" id="text-org2b9a465">
<p>
The manipulation of the rows and columns can be broken down into 3 types of <b>elementary matrices</b> that when multiplied with our <b>linear systems</b> will generate <b>equivalent</b> matrices (<b>E</b>). 
</p>

<p>
<i>(from page 134)</i>
When applied from the <i>left</i> <b>EA=B</b> it performs a row operation and makes a <b>row equivalent</b> matrix.<br>
When applied from the <i>right</i> <b>AE=B</b> it performs a column operation and makes a <b>column equivalent</b> matrix.<br>
</p>

<p>
Row/column operations are ofcourse reversible and therefore <b>E</b> is invertible and a <b>E<sup>-1</sup></b> always exists.
</p>

<p>
So now, waving our hands a little, given a non-singular matrix we can restate <i>Gauss-Jordan elimination</i> as "a bunch of row operations that turn our matrix into the identity matrix". Ie: <b>E<sub>k</sub>..E<sub>2</sub>E<sub>1</sub>A=I</b><br>
And thanks to each operations' invertibility we can flip it to be <b>A=E<sub>1</sub><sup>-1</sup>E<sub>2</sub><sup>-1</sup>..E<sub>k</sub><sup>-1</sup></b><br>
So Gauss-Jordan elimination for non-singular matrices has given us our first decomposition of sorts! We now know that every non-singular matrix can be written as a chain of row (or column) operations.
</p>

<p>
Row/Column operations come in 3 flavors
</p>
</div>
<div id="outline-container-orgf9fe47a" class="outline-4">
<h4 id="orgf9fe47a">Type I - Row/Column Interchange</h4>
<div class="outline-text-4" id="text-orgf9fe47a">
<p>
Interchaning rows (or columns) <i>i</i> and <i>j</i>
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-elementary-interchange</span> (rowcol1 rowcol2 rank<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Make an elementary row/column interchange matrix for ROWCOL1 and ROWCOL2 (ZERO indexed)"</span>
  (<span style="color: #0000FF;">let</span> ((u
         (matrix-subtract
          (matrix-unit-column rowcol1 rank<span style="color: #999999;">)</span>
          (matrix-unit-column rowcol2 rank<span style="color: #999999;">))))</span>
  (matrix-subtract
   (matrix-identity rank<span style="color: #999999;">)</span>
   (matrix-product
    u
    (matrix-transpose u<span style="color: #999999;">)))))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-elementary-interchange-inverse</span> (rowcol1 rowcol2 rank<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Make the inverse of the elementary row/column interchange matrix for ROWCOL1 and ROWCOL2 (ZERO indexed). This is identical to (matrix-elementary-interchange)"</span>
  (matrix-elementary-interchange
   rowcol1
   rowcol2
   rank<span style="color: #999999;">))</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org52284e2" class="outline-4">
<h4 id="org52284e2">Type II - Row/Column Multiple</h4>
<div class="outline-text-4" id="text-org52284e2">
<p>
Multiplying row (or column) <i>i</i> by <i>&alpha;</i>
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-elementary-multiply</span> (rowcol scalar rank<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Make an elementary row/column multiple matrix for a given ROWCOL (ZERO indexed)"</span>
  (<span style="color: #0000FF;">let</span> ((elementary-column
         (matrix-unit-column rowcol rank<span style="color: #999999;">)))</span>
  (matrix-subtract
   (matrix-identity rank<span style="color: #999999;">)</span>
   (matrix-product
    elementary-column
    (matrix-scalar-product
     (matrix-transpose elementary-column<span style="color: #999999;">)</span>
     (- 1 scalar<span style="color: #999999;">))))))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-elementary-multiply-inverse</span> (rowcol scalar rank<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Make the inverseof the elementary row/column multiple matrix for a given ROWCOL (ZERO indexed)"</span>
  (matrix-elementary-multiply
   rowcol
   (/ 1 scalar<span style="color: #999999;">)</span>
   rank<span style="color: #999999;">))</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org42f005f" class="outline-4">
<h4 id="org42f005f">Type III - Row/Column Addition</h4>
<div class="outline-text-4" id="text-org42f005f">
<p>
Adding a multiple of a row (or column) <i>i</i> to row (or column) <i>j</i>
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-elementary-addition</span> (rowcol1 rowcol2 scalar rank<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Make an elementary row/column product addition matrix. Multiply ROWCOL1 (ZERO indexed) by SCALAR and add it to ROWCOL2 (ZERO indexed)"</span>
  (matrix-add
   (matrix-identity rank<span style="color: #999999;">)</span>
   (matrix-scalar-product
    (matrix-product
     (matrix-unit-column rowcol2 rank<span style="color: #999999;">)</span>
     (matrix-transpose
      (matrix-unit-column rowcol1 rank<span style="color: #999999;">)))</span>
    scalar<span style="color: #999999;">)))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-elementary-addition-inverse</span> (rowcol1 rowcol2 scalar rank<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Make the inverse of the elementary row/column product addition matrix. Multiply ROWCOL1 (ZERO indexed) by SCALAR and add it to ROWCOL2 (ZERO indexed)"</span>
  (matrix-elementary-addition
   rowcol1
   rowcol2
   (- scalar<span style="color: #999999;">)</span>
   rank<span style="color: #999999;">))</span>
</pre>
</div>
</div>
</div>
</div>
</div>

<div id="outline-container-orgd7008e5" class="outline-2">
<h2 id="orgd7008e5">The LU Decomposition</h2>
<div class="outline-text-2" id="text-orgd7008e5">
</div>
<div id="outline-container-org1e88c73" class="outline-3">
<h3 id="org1e88c73">Gaussian elimination in matrix form</h3>
<div class="outline-text-3" id="text-org1e88c73">
<p>
If linear equations at their simplest take inputs and produce some outputs, then Gaussian elimination is our method of reversing the process. It's a systematic way for taking a known linear system with a given output and solving for its input. Because we know that adding and scaling equations preserves equalities, Gaussian elimination is a scheme for combining and swapping equations so that they reduce to something simpler which can be solved directly. We do this by elimination factors in our equations such that the last one is of the form <b>&alpha;x=b</b>. Equalities being preserved, we can use this simple equation to solve for one of the unknown inputs. Each of the remaining equation includes just one additional unknow input so that through back-substitution we can then solve for all of them one by one. 
</p>

<p>
So if <b>Ax=b</b> is our original system of equations in matrix form, then after Gaussian elimination we can write our simplified systm as <b>Ux=b<sub>new</sub></b>. Combining our equations has changed our output values, so the <b>b</b> has changes as well.
</p>

<p>
<i>From the Example on page 141</i> <br>
So if we started with an <b>A</b> that looked like this
</p>
\begin{bmatrix}
2 & 2 & 2\\
4 & 7 & 7\\
6 & 18 & 22\\
\end{bmatrix}
<p>
Gaussian elimination will give us a <b>U</b> that look like this:
</p>
\begin{bmatrix}
2 & 2 & 2\\
0 & 3 & 3\\
0 & 0 & 4\\
\end{bmatrix}
<p>
Looking at the system of equations <b>Ux=b<sub>new</sub></b> and  given a <b>b<sub>new</sub></b> we can see that the last row in <b>U</b> - [ 0 0 4 ] times the column [ x<sub>1</sub> x<sub>2</sub> x<sub>3</sub> ]<sup>T</sup> gives us a direct solution for x<sub>3</sub>. Then using <b>x<sub>3</sub></b> and the previous row/equation we could solve for <b>x<sub>2</sub></b> and so on.
</p>

<p>
Combining and swapping rows is something we just learned how to do using elementary matrices- so by cleverly taking their product with our matrix <b>A</b> we will be able to generate the <b>U</b> matrix - in effect reenacting Gaussian elimination using matrix multiplication. If each row manipulation is some elementary matrix <b>R<sub>n</sub></b> we could write out the process of Gaussian elimination as a series of products <b>R<sub>n</sub>R<sub>&#x2026;</sub>R<sub>2</sub>R<sub>1</sub>A=U</b>. Looking at <b>Ax=b</b> it's just the same - we simply multiply by both sides by the <b>R</b> matrices <b>R<sub>n</sub>R<sub>&#x2026;</sub>R<sub>2</sub>R<sub>1</sub>(Ax)=R<sub>1</sub>R<sub>2</sub>R<sub>&#x2026;</sub>R<sub>n</sub>b</b>. As we were hoping for, the left side will be <b>Ux</b> and the right hand side is our <b>b<sub>new</sub></b>.
</p>

<p>
On a high level the reduction of the equations happens in two repeated steps on each column: First we adjust the pivot and then we eliminate all the factors below it. In the matrix representation this is equivalent to adjusting the diagonal element and then making all the values below it equal to zero. The combination of the two <b>reduces the column</b> and make our system simpler. 
</p>

<blockquote>
<p>
<b>Note:</b> Gaussian elimination will only produce a solution for nonsingular square matrices, so the process described only holds for this case
</p>
</blockquote>
</div>
<div id="outline-container-orga4278ab" class="outline-4">
<h4 id="orga4278ab">Elementary Lower Triangular Matrics</h4>
<div class="outline-text-4" id="text-orga4278ab">
<p>
The example I used above was done without adjusting any pivots. We reducing the first column by simply eliminated the values below the <code>2</code> (in the upper left) and we could have done that by multiply our <b>A</b> by two <code>Type III</code> <b>elementary matrices</b> from the left like so:
</p>
\begin{equation}
\begin{bmatrix}
1 & 0 & 0\\
-2 & 1 & 0\\
0 & 0 & 1\\
\end{bmatrix}
\begin{bmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
-3 & 0 & 1\\
\end{bmatrix}
\begin{bmatrix}
2 & 2 & 2\\
4 & 7 & 7\\
6 & 18 & 22\\
\end{bmatrix}
=
\begin{bmatrix}
2 & 2 & 2\\
0 & 3 & 3\\
0 & 12 & 16\\
\end{bmatrix}
\end{equation}
<p>
The two <code>Type III</code> <b>elementary matrices</b> on the left are pretty simple and you can visually see what the <code>-2</code> and <code>-3</code> represent. They match the entry in <b>A</b> at the same index (row/column), but divided by the value of the pivot (ie: the factor that will eliminate the value). The result is that the first column has been reduced and we are closer to our upper triangular <b>U</b>
</p>

<p>
Constructing these simple <code>Type III</code> matrices is quick and inverting them is as easy as flipping the sign on the factor (ie. if you subtract some multiple of an equation from another, to reverse the operation you'd simply add the same multiple of the equation back)
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-elementary-row-elimination</span> (matrix row column<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Make a matrix that will eliminate an element at the specified ROW/COLUMN (ZERO indexed) using the diagonal element in the same column (typically the pivot)"</span>
  (<span style="color: #0000FF;">let</span>
      ((pivot (matrix-get-value matrix column column<span style="color: #999999;">))</span>
       (element-to-eliminate (matrix-get-value matrix row column<span style="color: #999999;">)))</span>
    (matrix-elementary-addition
     column
     row
     (-
      (/
       element-to-eliminate
       pivot<span style="color: #999999;">))</span>
     (matrix-rows matrix<span style="color: #999999;">))))</span>

</pre>
</div>

<p>
Looking again at the product of 2 <code>Type III</code> matrices with our <b>A</b>, and using what we know about composing linear systems, we already know that we can take the product of the first two matrices separately. Whatever matrix comes out we can then multiply times <b>A</b> to give us the same result.
</p>
\begin{equation}
\begin{pmatrix}
\begin{bmatrix}
1 & 0 & 0\\
-2 & 1 & 0\\
0 & 0 & 1\\
\end{bmatrix}
\begin{bmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
-3 & 0 & 1\\
\end{bmatrix}
\end{pmatrix}
\begin{bmatrix}
2 & 2 & 2\\
4 & 7 & 7\\
6 & 18 & 22\\
\end{bmatrix}
=
\begin{bmatrix}
2 & 2 & 2\\
0 & 3 & 3\\
0 & 12 & 16\\
\end{bmatrix}
\end{equation}


\begin{equation}
\begin{bmatrix}
1 & 0 & 0\\
-2 & 1 & 0\\
-3 & 0 & 1\\
\end{bmatrix}
\begin{bmatrix}
2 & 2 & 2\\
4 & 7 & 7\\
6 & 18 & 22\\
\end{bmatrix}
=
\begin{bmatrix}
2 & 2 & 2\\
0 & 3 & 3\\
0 & 12 & 16\\
\end{bmatrix}
\end{equation}

<p>
The result is surprisingly simple and we can see that we didn't really need to carry out the whole matrix product b/c we've simply merged the factors into one matrix. So we can simply build these matrices that eliminate entire columns and skip making tons of <code>Type III</code> matrices entirely. The new combined matrices are called <b>Elementary Lower-Triangular Matrix</b> and are described on <i>page 142</i>.
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-elementary-lower-triangular</span> (matrix column-to-clear<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Make a matrix that will eliminate all rows in a column below the diagonal (pivot position)"</span>

  (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-elementary-lower-triangular-rec</span> (matrix column-to-clear row-to-build rank<span style="color: #999999;">)</span>
    <span style="color: #036A07;">"Recursive function to build the elementary lower triangular matrix"</span>
    (<span style="color: #0000FF;">cond</span>
     ((equal
       rank
       row-to-build) <span style="color: #8D8D84;">; </span><span style="color: #8D8D84; font-style: italic;">Done building the matrix</span>
      '(<span style="color: #999999;">))</span>
     ((&lt;=
       row-to-build
       column-to-clear) <span style="color: #8D8D84;">; </span><span style="color: #8D8D84; font-style: italic;">Building the simply "identity" portion above the pivot</span>
      (matrix-append
       (matrix-unit-row row-to-build rank<span style="color: #999999;">)</span>
       (matrix-elementary-lower-triangular-rec
        matrix
        column-to-clear
        (1+ row-to-build<span style="color: #999999;">)</span>
        rank<span style="color: #999999;">)))</span>
     (t <span style="color: #8D8D84;">; </span><span style="color: #8D8D84; font-style: italic;">Build the elimination portion below the pivot</span>
      (<span style="color: #0000FF;">let</span>
          ((pivot (matrix-get-value matrix column-to-clear column-to-clear<span style="color: #999999;">))</span>
           (element-to-eliminate (matrix-get-value matrix row-to-build column-to-clear<span style="color: #999999;">)))</span>
        (<span style="color: #0000FF;">let</span>
            ((cancellation-factor (-
                                   (/
                                    element-to-eliminate
                                    pivot<span style="color: #999999;">))))</span>
          (matrix-append
           (matrix-add
            (matrix-unit-row row-to-build rank<span style="color: #999999;">)</span>
            (matrix-scalar-product
             (matrix-unit-row column-to-clear rank<span style="color: #999999;">)</span>
             cancellation-factor<span style="color: #999999;">))</span>
           (matrix-elementary-lower-triangular-rec
            matrix
            column-to-clear
            (1+ row-to-build<span style="color: #999999;">)</span>
            rank<span style="color: #999999;">)))))))</span>

  (matrix-elementary-lower-triangular-rec
   matrix
   column-to-clear
   0
   (matrix-rows matrix<span style="color: #999999;">)))</span>

</pre>
</div>
</div>
</div>

<div id="outline-container-org0cc08e3" class="outline-4">
<h4 id="org0cc08e3">Building the <b>L</b> Matrix</h4>
<div class="outline-text-4" id="text-org0cc08e3">
<p>
So now our product of elementary matrices <b>R<sub>n</sub>R<sub>&#x2026;</sub>R<sub>2</sub>R<sub>1</sub>A=U</b> shortens to something similar <b>G<sub>r</sub>G<sub>&#x2026;</sub>G<sub>2</sub>G<sub>1</sub>A=U</b>, but where each <i>Elementary Lower-Triangular Matrix</i> <b>G</b> takes the place of several <b>R</b> matrices. The product <b>G<sub>r</sub>G<sub>&#x2026;</sub>G<sub>2</sub>G<sub>1</sub></b> involved a lot of matrix products, but fortunately we have a shortcut. These <b>G</b> matrices have the property that their inverse is just a matter of flipping the sign of the factors' in their column. You can confirm this by inverting our definition <b>G=R<sub>n</sub>R<sub>&#x2026;</sub>R<sub>2</sub>R<sub>1</sub></b> and remembering that the <b>R</b>'s just involve a sign flip and <b>R<sup>-1</sup></b>'s are also <code>Type III</code> matrices. 
</p>

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-invert-elementary-lower-triangular</span> (matrix-elementary-lower-triangular<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Inverts an L matrix by changing the sign on all the factors below the diagonal"</span>
  (matrix-add
   (matrix-scalar-product
    matrix-elementary-lower-triangular
    -1<span style="color: #999999;">)</span>
   (matrix-scalar-product
    (matrix-identity
     (matrix-rows matrix-elementary-lower-triangular<span style="color: #999999;">))</span>
    2<span style="color: #999999;">)))</span>
</pre>
</div>
<blockquote>
<p>
<b>TODO</b>: Add a function to build the inverse directly
</p>
</blockquote>


<p>
This allows us to take our equation <b>G<sub>1</sub>G<sub>2</sub>G<sub>&#x2026;</sub>G<sub>n</sub>A=U</b> and trivially produce the interesting equality <b>A=G<sup>-1</sup><sub>1</sub>G<sup>-1</sup><sub>2</sub>G<sup>-1</sup><sub>&#x2026;</sub>G<sub>n</sub>U</b> without having to compute a single value; just flip the order of the product and flup the signs. Now the product <b>G<sup>-1</sup><sub>1</sub>G<sup>-1</sup><sub>2</sub>G<sup>-1</sup><sub>&#x2026;</sub>G<sub>n</sub></b> is special and <i>page 143</i> describes how all the factors just move into one matrix without having to do any calculation. (<b>Note</b>: that the same doesn't hold for the non-inverted product of the <b>G</b>'s!) The combined product produces the lower triangular matrix <b>L</b> and lets us write down <b>A=LU</b> - from which we get the name of the decomposition. (see <i>page 143-144</i> <b><i>eq 3.10.6</i></b> )
</p>

<p>
To finish our example we will first add another matrix to the left to eliminate the second column in <b>A</b> so that we have the equation <b>G<sub>2</sub>G<sub>1</sub>A=U</b>
</p>

\begin{equation}
\begin{bmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
0 & -4 & 1\\
\end{bmatrix}
\begin{bmatrix}
1 & 0 & 0\\
-2 & 1 & 0\\
-3 & 0 & 1\\
\end{bmatrix}
\begin{bmatrix}
2 & 2 & 2\\
4 & 7 & 7\\
6 & 18 & 22\\
\end{bmatrix}
=
\begin{bmatrix}
2 & 2 & 2\\
0 & 3 & 3\\
0 & 0 & 4\\
\end{bmatrix}
\end{equation}

<blockquote>
<p>
<b>Note</b> that the factor of <code>-4</code> was only deduced after doing the reduction of the first column which had given us:
</p>

\begin{bmatrix}
2 & 2 & 1\\
0 & 3 & 3\\
0 & 12 & 16\\
\end{bmatrix}

<p>
So you can't reduce the second column before you'd reduced the first!
</p>
</blockquote>

<p>
Next we invert our two 2 <b>G</b> matrices and bring them to other side to get <b>A=G<sub>1</sub><sup>-1</sup>G<sub>2</sub><sup>-1</sup>U</b> (Notice how the order of the <b>G</b>'s has changed b/c of the inversion)
</p>

\begin{equation}
\begin{bmatrix}
2 & 2 & 2\\
4 & 7 & 7\\
6 & 18 & 22\\
\end{bmatrix}
=
\begin{bmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 4 & 1\\
\end{bmatrix}
\begin{bmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
3 & 0 & 1\\
\end{bmatrix}
\begin{bmatrix}
2 & 2 & 2\\
0 & 3 & 3\\
0 & 0 & 4\\
\end{bmatrix}
\end{equation}

<p>
Now multiplying the two inverted matrices is quick and easy b/c we just need to merge the factors into one matrix:
</p>

\begin{equation}
\begin{bmatrix}
2 & 2 & 2\\
4 & 7 & 7\\
6 & 18 & 22\\
\end{bmatrix}
=
\begin{pmatrix}
\begin{bmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 4 & 1\\
\end{bmatrix}
\begin{bmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
3 & 0 & 1\\
\end{bmatrix}
\end{pmatrix}
\begin{bmatrix}
2 & 2 & 2\\
0 & 3 & 3\\
0 & 0 & 4\\
\end{bmatrix}
\end{equation}


\begin{equation}
\begin{bmatrix}
2 & 2 & 2\\
4 & 7 & 7\\
6 & 18 & 22\\
\end{bmatrix}
=
\begin{bmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
3 & 4 & 1\\
\end{bmatrix}
\begin{bmatrix}
2 & 2 & 2\\
0 & 3 & 3\\
0 & 0 & 4\\
\end{bmatrix}
\end{equation}

<p>
And we are left with <b>A=LU</b>
</p>

<p>
When we do this is code we immediately invert the <b>G</b>'s and build up their product. So as we eliminate <b>A</b> column after column and turn it into the upper triangular <b>U</b> we are in parallel accumulating the inverse of the elimination matrices into <b>L</b>. The function will return us two matrices, <b>L</b> and <b>U</b>
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-LU-decomposition</span> (matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Perform Gaussian elimination on MATRIX and return the list (L U), representing the LU-decomposition. If a zero pivot is hit, we terminate and return a string indicating that"</span>
  (<span style="color: #0000FF;">let</span>
      ((rank
        (matrix-rows matrix<span style="color: #999999;">)))</span>
    (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-LU-decomposition-rec</span> (L-matrix
                                        reduced-matrix
                                        column-to-eliminate<span style="color: #999999;">)</span>
      (<span style="color: #0000FF;">cond</span>
       ((equal column-to-eliminate rank<span style="color: #999999;">)</span>
        (list L-matrix reduced-matrix<span style="color: #999999;">))</span>
       ((zerop
         (matrix-get-value
          reduced-matrix
          column-to-eliminate
          column-to-eliminate<span style="color: #999999;">))</span>
        <span style="color: #008000;">"ERROR: LU decomposition terminated due to hitting a zero pivot. Consider using the PLU"</span><span style="color: #999999;">)</span>
       (t
        (<span style="color: #0000FF;">let</span> ((column-elimination-matrix (matrix-elementary-lower-triangular
                                          reduced-matrix
                                          column-to-eliminate<span style="color: #999999;">)))</span>
          (matrix-LU-decomposition-rec
           (matrix-product
            L-matrix
            (matrix-invert-elementary-lower-triangular
             column-elimination-matrix<span style="color: #999999;">))</span>
           (matrix-product
            column-elimination-matrix
            reduced-matrix<span style="color: #999999;">)</span>
           (1+ column-to-eliminate<span style="color: #999999;">))))))</span>

    (matrix-LU-decomposition-rec
     (matrix-identity rank<span style="color: #999999;">)</span>
     matrix
     0<span style="color: #999999;">)))</span>
</pre>
</div>
<blockquote>
<p>
<b>TODO:</b> I'm updating <b>L</b> by doing a a product here (ie. <b>L<sub>new</sub> = G<sup>-1</sup>L<sub>old</sub></b>).. but the whole point is that <b>L</b> can be updated without a product. This could use a helper function that would build/update <b>L</b>'s
</p>

<p>
Updating <b>U</b> could also be done without doing a whole matrix product and just looking at the lower submatrix
</p>
</blockquote>
</div>
</div>

<div id="outline-container-orgdc22ae2" class="outline-4">
<h4 id="orgdc22ae2">Partial Pivoting</h4>
<div class="outline-text-4" id="text-orgdc22ae2">
<p>
Now while in previous section we managed to decompose <b>A</b> into two matrices <b>L</b> and <b>U</b>, you may have noticed there is an error condition our code. The issue is that we may find that after performing elimination on a column we are left with a zero in the next column's pivot position. This makes it impossible to eliminate the factors below it. The solution we have from <i>Gaussian Elimination</i> is to swap in a row from below so that the pivot is non-zero. We are going to take advantage of this and use the strategy called <b>partial pivoting</b> and will swap in to the pivot position whichever row has the maximal value for that column. It will ensure that our results have less error and like any row-swap can be done pretty easily with a <code>Type I</code> elementary matrix.
</p>

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-partial-pivot</span> (matrix pivot-column<span style="color: #999999;">)</span>
    <span style="color: #036A07;">"Returns a Type-I matrix that will swap in the row under the pivot that has maximal magnititude"</span>
    (<span style="color: #0000FF;">let</span> ((column-below-pivot (matrix-submatrix
                               matrix
                               pivot-column
                               pivot-column
                               (matrix-rows matrix<span style="color: #999999;">)</span>
                               (1+ pivot-column<span style="color: #999999;">))))</span>
      (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">find-max-index</span> (data-list max-val max-index current-index<span style="color: #999999;">)</span>
        (<span style="color: #0000FF;">cond</span>
         ((null data-list<span style="color: #999999;">)</span>
          max-index<span style="color: #999999;">)</span>
         ((&gt;
           (abs(car data-list<span style="color: #999999;">))</span>
           max-val<span style="color: #999999;">)</span>
          (find-max-index
           (cdr data-list<span style="color: #999999;">)</span>
           (abs(car data-list<span style="color: #999999;">))</span>
           current-index
           (1+ current-index<span style="color: #999999;">)))</span>
         (t
          (find-max-index
           (cdr data-list<span style="color: #999999;">)</span>
           max-val
           max-index
           (1+ current-index<span style="color: #999999;">)))))</span>

     (matrix-elementary-interchange
      pivot-column
      (+
       pivot-column
       (find-max-index
        (matrix-data column-below-pivot<span style="color: #999999;">)</span>
        0
        0
        0<span style="color: #999999;">))</span>
      (matrix-rows matrix<span style="color: #999999;">))))</span>
</pre>
</div>

<p>
So if <b>G<sub>n</sub></b> were the <i>elementary lower-triangular matrices</i> from the last section that performed our eliminations and <b>F<sub>n</sub></b> are the new <b>Type I</b> pivot adjustments then if we adjust our pivot before each elimination, our reduction needs to be rewritten as <b>G<sub>1</sub>F<sub>1</sub>G<sub>2</sub>F<sub>2</sub>..G<sub>r</sub>F<sub>r</sub>A=U</b> where each <b>G</b> <b>F</b> pair corresponds to a reduction of a column: <b>(G<sub>1</sub>F<sub>1</sub>)<sub>col<sub>1</sub></sub>(G<sub>2</sub>F<sub>2</sub>)<sub>col<sub>2</sub></sub>..(G<sub>r</sub>F<sub>r</sub>)<sub>col<sub>r</sub></sub>A=U</b>. 
</p>

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-reduce-column</span> (matrix column-to-reduce<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Adjusts the pivot using partial pivoting and eliminates the elements in one column. Returns a list of the elimination matrix, permutation matrix and the resulting matrix with reduced column (list of 3 matrices)"</span>
  (<span style="color: #0000FF;">let*</span>
      ((pivot-adjusting-matrix
        (matrix-partial-pivot
         matrix
         column-to-reduce) <span style="color: #999999;">)</span>
       (matrix-with-partial-pivoting
        (matrix-product <span style="color: #8D8D84;">; </span><span style="color: #8D8D84; font-style: italic;">pivot!</span>
         pivot-adjusting-matrix
         matrix<span style="color: #999999;">))</span>
       (column-elimination-matrix
        (matrix-elementary-lower-triangular
         matrix-with-partial-pivoting
         column-to-reduce<span style="color: #999999;">))</span>
       (matrix-with-reduced-column
        (matrix-product <span style="color: #8D8D84;">; </span><span style="color: #8D8D84; font-style: italic;">reduce</span>
         column-elimination-matrix
         matrix-with-partial-pivoting<span style="color: #999999;">)))</span>
    (list column-elimination-matrix pivot-adjusting-matrix matrix-with-reduced-column<span style="color: #999999;">)))</span>
</pre>
</div>
<blockquote>
<p>
<b>TODO</b>: Return <b>G<sup>-1</sup></b> instead, because it's more directly what we need later
</p>
</blockquote>

<p>
Turning back to our orginal <b>Ax=b</b> we can again generate the <b>b<sub>new</sub></b>: <b>Ux=(G<sub>1</sub>F<sub>1</sub>)<sub>col<sub>1</sub></sub>(G<sub>2</sub>F<sub>2</sub>)<sub>col<sub>2</sub></sub>..(G<sub>r</sub>F<sub>r</sub>)<sub>col<sub>r</sub></sub>b</b>  -&gt;  <b>Ux=b<sub>new</sub></b>. Then again using back substitution we can get a solution for <b>x</b>&#x2026;.  However this solution has some serious flaws. Looking at <b>(G<sub>1</sub>F<sub>1</sub>)<sub>col<sub>1</sub></sub>(G<sub>2</sub>F<sub>2</sub>)<sub>col<sub>2</sub></sub>..(G<sub>r</sub>F<sub>r</sub>)<sub>col<sub>r</sub></sub></b> we can no longer use the inversion trick to copy factors together. We seem to be foreced to carry out a whole lot of matrix products. Before we added the pivots in, we had manage to get a clean equation <b>A=LU</b>, and <b>L</b> was especially easy to make without carrying out a single matrix product - but now building that decomposition suddenly isn't as easy!
</p>
</div>
</div>

<div id="outline-container-org1b98301" class="outline-4">
<h4 id="org1b98301">Extracting the pivots</h4>
<div class="outline-text-4" id="text-org1b98301">
<p>
On <i>page 150</i> the book shows us how we can fix this situation by extracting the partial pivots out of column reductions so that instead of: <b>G<sub>1</sub>F<sub>1</sub>G<sub>2</sub>F<sub>2</sub>..G<sub>r</sub>F<sub>r</sub>A=U</b> we are left with something that looks more like  <b>G<sub>1</sub>G<sub>2</sub>..G<sub>r</sub>F<sub>1</sub>F<sub>2</sub>..F<sub>r</sub>A=U</b>. With the <b>G</b>'s together we can use our inversion trick to get our easily-computed <b>L</b> back. Then taking the product of the <b>F</b>'s gives us a new <i>permutation matrix</i> <b>P</b> so that our final equation will look like <b>PA=LU</b>. Looking at the book's solution from a different perspective, the reason we've had the matrices interleaved is because that's how we build them (from right to left). We can't go into the middle of the matrix and adjust the pivot position till we'd carried out all the eliminations in the columns before it. The previous eliminations will mix up the rows and change all the values in that column so the maximal value won't be known ahead of time. So the <i>GFGFGF</i> sequence for building the reduction matrices (from right to left, column by column)  needs to be observed. The trick is that once we've finished Gaussian elimination then we know the final order of the rows in <b>U</b> and what <i>page 150</i> demonstrates is that if we know the row interchanges, we can actually carry them out first as long as we then fix-up any <i>preceding</i> eliminations matrices a bit. Specifically if you adjust some pivot <i>k</i> by swapping it with row <i>k+i</i> then any <i>previous</i> eliminations that involved the row <i>k</i> (and row <i>k+i</i>) now needs to be fixed to reflect that you'll be doing the row interchange ahead of time.
</p>

<p>
While the <b>G<sub>1</sub>G<sub>2</sub>..G<sub>r</sub>F<sub>1</sub>F<sub>2</sub>..F<sub>r</sub>A=U</b> representation is really handy, we would like to build matrices as-we-go and not have to build the interleaved mess and then have to spend time fixing it.
</p>

<p>
The strategy is that as we <i>pivot-adjust</i> and <i>eliminate</i> and <i>pivot-adjust</i> and <i>eliminate</i> column by column, slowly building up our <b>U</b> matrix, each time we <i>pivot-adjust</i> we build our permuation matrix <b>P</b> by accumulating the products of the <b>F</b>'s and we fix-up the preceeding eliminations. The way it's described in the book, they seem to update all the <b>G</b> matrices that came before - however my shortcut is to skip all the <b>G</b>'s and go straight to building the <b>L</b> matrix and to adjust the rows there. Just as before with the plain LU decompostion, every <b>G</b> we get during elimination is inverting it to <b>G<sup>-1</sup></b>, and then added it to <b>L</b> so that <b>L<sub>new</sub> = L<sub>old</sub>G<sup>-1</sup></b>. The extra step is that now each time we adjust a pivot with a new <b>F</b> we update <b>L</b> such that <b>L<sub>new</sub>=FL<sub>old</sub>F</b>.
</p>

<blockquote>
<p>
To see why this is equivalent to updating all the <b>G</b>'s and then inverting at the end, rememeber that <b>F=F<sup>-1</sup></b> b/c a row exchange is it's own inverse. So <b>F<sup>2</sup>=I</b>. So if we have are in the middle of Gaussian elimination and have <b>G<sub>3</sub>G<sub>2</sub>G<sub>1</sub>A=U</b> and we then  do a pivot adjustment <b>FG<sub>3</sub>G<sub>2</sub>G<sub>1</sub>A=U</b> then we can insert a identity matrix <b>FG<sub>3</sub>G<sub>2</sub>G<sub>1</sub>IA=U</b> expand it to <b>FF</b> so that <b>FG<sub>3</sub>G<sub>2</sub>G<sub>1</sub>FFA=U</b> then bring everything to the other side <b>FA=F<sup>-1</sup>G<sub>1</sub><sup>-1</sup>G<sub>2</sub><sup>-1</sup>G<sub>3</sub><sup>-1</sup>F<sup>-1</sup>U</b> recover our easy-to-compute <b>L</b> matrix <b>FA=F<sup>-1</sup>LF<sup>-1</sup>U</b> simplify our <b>F<sup>-1</sup></b>'s so that <b>FA=FLFU</b> and we have our new <b>L</b> in <b>FA=L<sub>new</sub>U</b> ie. <b>L<sub>new</sub>=FL<sub>old</sub>F</b>
</p>
</blockquote>

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-update-L-matrix</span> (elementary-lower-triangular-matrix type-i-interchange-matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Take an elementary lower triangular matrix and update it to match a row interchange between ROW1 and ROW2 (ZERO indexed)"</span>
    (matrix-product
     type-i-interchange-matrix
     (matrix-product
      elementary-lower-triangular-matrix
      type-i-interchange-matrix<span style="color: #999999;">)))</span>
</pre>
</div>
<blockquote>
<p>
<b>TODO</b>: Update to not do two full matrix products. This can be do with some clever number swapping instead
</p>
</blockquote>

<p>
So our method will still go reducing the matrix column by column and building up <b>U</b>, but in parallel we will be building <b>L</b> and <b>P</b>. So the result will be the three matrices (<b>P</b> <b>L</b> <b>U</b>).
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-PLU-decomposition</span> (matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Perform Gaussian elimination with partial pivoting on MATRIX and return the list (P L U), representing the LU-decomposition "</span>
  (<span style="color: #0000FF;">let</span>
      ((rank
        (matrix-rows matrix<span style="color: #999999;">)))</span>
    (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-PLU-decomposition-rec</span> (P-matrix
                                        L-matrix
                                        reduced-matrix
                                        column-to-reduce<span style="color: #999999;">)</span>
      (<span style="color: #0000FF;">cond</span>
       ((equal
         column-to-reduce
         rank<span style="color: #999999;">)</span>
        (list P-matrix L-matrix  reduced-matrix<span style="color: #999999;">))</span>
       (t
        (<span style="color: #0000FF;">let</span>
            ((current-column-reduction-matrices
              (matrix-reduce-column
               reduced-matrix
               column-to-reduce<span style="color: #999999;">)))</span>
          (matrix-PLU-decomposition-rec
           (matrix-product                              <span style="color: #8D8D84;">; </span><span style="color: #8D8D84; font-style: italic;">update the permutation matrix</span>
            (second current-column-reduction-matrices<span style="color: #999999;">)</span>
            P-matrix<span style="color: #999999;">)</span>
           (matrix-product
            (matrix-update-L-matrix       <span style="color: #8D8D84;">; </span><span style="color: #8D8D84; font-style: italic;">update elimination matrices due to partial pivot</span>
             L-matrix
             (second current-column-reduction-matrices<span style="color: #999999;">))</span>
            (matrix-invert-elementary-lower-triangular (first current-column-reduction-matrices<span style="color: #999999;">)))</span>
           (third current-column-reduction-matrices)    <span style="color: #8D8D84;">; </span><span style="color: #8D8D84; font-style: italic;">the further reduced matrix</span>
           (1+ column-to-reduce<span style="color: #999999;">))))))</span>

    (matrix-PLU-decomposition-rec
     (matrix-identity rank<span style="color: #999999;">)</span>
     (matrix-identity rank<span style="color: #999999;">)</span>
     matrix
     0<span style="color: #999999;">)))</span>
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org797eb20" class="outline-3">
<h3 id="org797eb20">Using the LU</h3>
<div class="outline-text-3" id="text-org797eb20">
<blockquote>
<p>
<b><i>Notes on getting a good numerical solution:</i></b>
</p>

<p>
<i>Section 1.5</i> goes into a good amount of detail of why floating point arithmetic will introduce errors and how to mitigate the problem. Partial pivoting will provide a bit of help, however it's also suggested to use <b>row-scaling</b> and <b>column-scaling</b>.
</p>

<p>
<b>Row-scaling</b> will alter the magnitude of the output value of your linear system, while <b>column scaling</b> will alter the scale of your inputs. Don't hesitate to have the inputs and outputs use different units. <i>page 28</i> suggests scaling the rows such that the maximum magnitude of each row is equal to <b>1</b> (ie. divide the row by the largest coefficient)
</p>

<p>
The topic of <i>residuals</i>, <i>sensitivity</i> and <i>coditioning</i> will be revisited later
</p>
</blockquote>
</div>


<div id="outline-container-orgc7999dc" class="outline-4">
<h4 id="orgc7999dc">Solving for x in Ax=b</h4>
<div class="outline-text-4" id="text-orgc7999dc">
<p>
Now that we can break a linear system <b>A</b> into two systems <b>L</b> and <b>U</b> we need to go back to where we started and solve for inputs given some outputs.We started with <b>Ax=b</b> and now we know we can do <b>PA=LU</b>. Combinding the two we can get <b>PAx=Pb</b> and then <b>LUx=Pb</b>. As mentioned before, <b>b<sub>new</sub>=Pb</b>, so for simplicity <b>LUx=b<sub>new</sub></b>. The new <b>b</b> has the same output values, just reordered a bit due to pivot adjustments. Since the order of the original equations generally doesn't have a special significance this is just a minor change.
</p>

<p>
Next we define a new intermediary vector <b>Ux=y</b> so that we can write <b>Ly=b<sub>new</sub></b>. This value we can solve directly by forward substitution. The first row of the lower triangular matrix gives us a simple solvable equation of the form <b>ax=b</b> and every subsequent row adds an additional unknown that we can solve for directly.
</p>

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-forward-substitution</span> (lower-triangular-matrix output-vector<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Solve for an input-vector using forward substitution. ie. solve for x in Lx=b where b is OUTPUT-VECTOR and L is the LOWER-TRIANGULAR-MATRIX"</span>
  (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-forward-substitution-rec</span> (lower-triangular-matrix input-vector-data output-vector-data row<span style="color: #999999;">)</span>
    (<span style="color: #0000FF;">cond</span>
     ((null output-vector-data) <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">BASE CASE</span>
      input-vector-data<span style="color: #999999;">)</span>
     (t                         <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">REST</span>
      (matrix-forward-substitution-rec
       lower-triangular-matrix
       (append
        input-vector-data
        (list
         (/
          (-
           (car output-vector-data<span style="color: #999999;">)</span>
           <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">on the first iteration this is the product of null vectors.. which in our implementation returns zero</span>
           (matrix-inner-product-data
            (matrix-data
             (matrix-extract-subrow
              lower-triangular-matrix
              row
              0
              row<span style="color: #999999;">))</span>
            input-vector-data<span style="color: #999999;">))</span>
          (matrix-get-value lower-triangular-matrix row row<span style="color: #999999;">))))</span>
       (cdr output-vector-data<span style="color: #999999;">)</span>
       (1+ row<span style="color: #999999;">)))))</span>

  (matrix-from-data-list
   (matrix-rows lower-triangular-matrix<span style="color: #999999;">)</span>
   1
   (matrix-forward-substitution-rec
    lower-triangular-matrix
    '(<span style="color: #999999;">)</span>
    (matrix-data output-vector<span style="color: #999999;">)</span>
    0<span style="color: #999999;">)))</span>
</pre>
</div>

<p>
Once we have <b>y</b> we can go to <b>Ux=y</b> and solve for <b>x</b> by back substitution
</p>

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-back-substitution</span> (upper-triangular-matrix output-vector<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Solve for an input-vector using forward substitution. ie. solve for x in Lx=b where b is OUTPUT-VECTOR and L is the LOWER-TRIANGULAR-MATRIX"</span>
  (matrix-from-data-list
   (matrix-rows upper-triangular-matrix<span style="color: #999999;">)</span>
   1
   (reverse
    (matrix-data
     (matrix-forward-substitution
      (matrix-from-data-list
       (matrix-rows upper-triangular-matrix<span style="color: #999999;">)</span>
       (matrix-rows upper-triangular-matrix) <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">rows == columns</span>
       (reverse (matrix-data upper-triangular-matrix<span style="color: #999999;">)))</span>
      (matrix-from-data-list
       (matrix-rows output-vector<span style="color: #999999;">)</span>
       1
       (reverse (matrix-data output-vector<span style="color: #999999;">))))))))</span>
</pre>
</div>
<blockquote>
<p>
<b>Not</b>: Here I'm using a bit of a trick to reuse the forward substitution function
</p>
</blockquote>

<p>
Now glueing everything together is now just a few lines of code
</p>

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-solve-for-input</span> (PLU output-vector<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Solve for x in Ax=b where b is OUTPUT-VECTOR and A is given factorized into PLU"</span>
  (<span style="color: #0000FF;">let*</span> ((permuted-output-vector (matrix-product (first PLU) output-vector<span style="color: #999999;">))</span>
         (intermediate-y-vector (matrix-forward-substitution (second PLU) permuted-output-vector<span style="color: #999999;">)))</span>
    (matrix-back-substitution (third PLU) intermediate-y-vector<span style="color: #999999;">)))</span>
</pre>
</div>
<blockquote>
<p>
<b>Note:</b> I have <i>PLU</i> as the input as opposed to <b>A</b> b/c we often want to solve <b>Ax=b</b> over and over for different values of <b>b</b> and we don't want to recompute <i>PLU</i>
</p>
</blockquote>
</div>

<ul class="org-ul">
<li><a id="org5fe239d"></a>EXAMPLE: Vandermonde matrices<br>
<div class="outline-text-5" id="text-org5fe239d">
<p>
For a good immediate usecase see <a href="./vandermonde.html">my explanation of the Vandermonde matrix</a> and how we can now fit polynomials to points (using the code we've just developed)
</p>
</div>
</li>
</ul>
</div>
<div id="outline-container-org3539968" class="outline-4">
<h4 id="org3539968">The LDU Decomposition</h4>
<div class="outline-text-4" id="text-org3539968">
<p>
As mention on <i>page 154</i>, the <b>LU</b> can be further broken down into <b>LDU</b> - where both <b>L</b> and <b>U</b> have <b>1</b>'s on the diagonal and <b>D</b> is a diagonal matrix with all the pivots. This has the nice property of being more symmetric.
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-LDU-decomposition</span> (matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Take the LU decomposition and extract the diagonal coefficients into a diagonal D matrix. Returns ( P L D U ) "</span>
  (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-extract-D-from-U</span> (matrix<span style="color: #999999;">)</span>
    <span style="color: #036A07;">"Extract the diagonal coefficients from an upper triangular matrix into a separate diagonal matrix. Returns ( D U ). D is diagonal and U is upper triangular with 1's on the diagonal"</span>
    (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-build-D-U-data</span> (matrix row D-data U-data<span style="color: #999999;">)</span>
      (<span style="color: #0000FF;">let</span> ((rank (matrix-rows matrix<span style="color: #999999;">))</span>
            (pivot (matrix-get-value matrix row row<span style="color: #999999;">)))</span>
        (<span style="color: #0000FF;">cond</span> ((equal row rank<span style="color: #999999;">)</span>
               (list D-data U-data) <span style="color: #999999;">)</span>
              (t
               (matrix-build-D-U-data
                matrix
                (1+ row<span style="color: #999999;">)</span>
                (nconc
                 D-data
                 (matrix-data
                  (matrix-scalar-product
                   (matrix-unit-row row rank<span style="color: #999999;">)</span>
                   pivot<span style="color: #999999;">)))</span>
                (nconc
                 U-data
                 (matrix-unit-rowcol-data row (1+ row<span style="color: #999999;">))</span>
                 (matrix-data
                  (matrix-scalar-product
                   (matrix-extract-subrow matrix row (1+ row) rank<span style="color: #999999;">)</span>
                   (/ 1.0 pivot<span style="color: #999999;">)))))))))</span>

    (<span style="color: #0000FF;">let</span> ((rank (matrix-rows matrix<span style="color: #999999;">))</span>
          (D-U-data (matrix-build-D-U-data matrix 0 '() '(<span style="color: #999999;">))))</span>
      (list
       (matrix-from-data-list rank rank (first D-U-data<span style="color: #999999;">))</span>
       (matrix-from-data-list rank rank (second D-U-data<span style="color: #999999;">)))))</span>

  (<span style="color: #0000FF;">let</span> ((LU-decomposition (matrix-LU-decomposition matrix<span style="color: #999999;">)))</span>
    (nconc
     (list
      (first LU-decomposition<span style="color: #999999;">))</span>
     (matrix-extract-D-from-U
      (second LU-decomposition<span style="color: #999999;">)))))</span>

</pre>
</div>
<p>
An extra nicety is that if <b>A</b> is symmetric then <b>A=A<sup>T</sup></b> and therefore <b>LDU=(LDU)<sup>T</sup>=U<sup>T</sup>D<sup>T</sup>L<sup>T</sup></b>. Since <b>D==D<sup>T</sup></b> and the <b>LU</b> factorization is unique then <b>L</b> must equal <b>U<sup>T</sup></b> and <b>U</b> is equal to <b>L<sup>T</sup></b> - so we can write <b>A=LDL<sup>T</sup></b>
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-is-symmetric</span> (matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Test if the matrix is symmetric"</span>
  (<span style="color: #0000FF;">let</span> ((transpose (matrix-transpose matrix<span style="color: #999999;">)))</span>
    (<span style="color: #0000FF;">let</span> ((A-data (matrix-data matrix<span style="color: #999999;">))</span>
          (A-transpose-data (matrix-data transpose<span style="color: #999999;">)))</span>
      (equal A-data A-transpose-data<span style="color: #999999;">))))</span>

</pre>
</div>
</div>
</div>

<div id="outline-container-orgc0742ff" class="outline-4">
<h4 id="orgc0742ff">The Cholesky Decomposition</h4>
<div class="outline-text-4" id="text-orgc0742ff">
<p>
Going one step further - if we have a symmetric matrix (so <b>A=LDL<sup>T</sup></b>) and all the pivots are positive, then we can break up the <b>D</b>  into 2 further matrices <b>D<sub>split</sub></b>. The <b>D<sub>split</sub></b> matrix will be like <b>D</b>, but instead each element on the diagonal (the pivots from the original <b>U</b> matrix) will be replaced by its square root - so that <b>D<sub>split</sub>D<sub>split</sub>=D</b>. This is taking advantage of the fact that a unit diagonal multiplied with itself simply squares the diagonal elements. Note here that if any of the diagonal elements are negative, then you can't really take the square root here b/c you'd get complex numbers.
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-is-positive-definite</span> (matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Test if the matrix is symmetric"</span>
  (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">is-no-data-negative</span> (data<span style="color: #999999;">)</span>
    (<span style="color: #0000FF;">cond</span> ((null data) t<span style="color: #999999;">)</span>
          ((&lt; (car data) 0) nil<span style="color: #999999;">)</span>
          (t (is-no-data-negative (cdr data<span style="color: #999999;">)))))</span>

  (<span style="color: #0000FF;">let*</span> ((LDU (matrix-DU-decomposition matrix<span style="color: #999999;">))</span>
         (D (third PLDU<span style="color: #999999;">)))</span>
    (<span style="color: #0000FF;">and</span> (matrix-is-symmetric matrix) (is-no-data-negative (matrix-data D<span style="color: #999999;">)))))</span>

</pre>
</div>

<p>
But if the pivots are positive, then we change <b>A=LDL<sup>T</sup></b> to <b>A=LD<sub>split</sub>D<sub>split</sub>L<sup>T</sup></b>. Notice that both halfs of the equation are similar. Remember that just like with <b>D</b>, <b>D<sub>split</sub>=D<sub>split</sub><sup>T</sup></b>. So we can rewrite <b>A=LD<sub>split</sub>D<sub>split</sub>L<sup>T</sup></b> as <b>A=LD<sub>split</sub>D<sub>split</sub><sup>T</sup>L<sup>T</sup></b>. Assigning a new matrix <b>R</b> to be equal to the product <b>LD<sub>split</sub></b> we can write down <b>A=RR<sup>T</sup></b>. This <b>R</b> will have the square-root coefficients on the diagonal b/c <b>L</b> has <b>1</b>'s on its own central diagonal. The text then demonstates that since turning <b>R</b> into the two matrices <b>LD<sub>split</sub></b> is unique, then given an decomposition <b>A=RR<sup>T</sup></b> where <b>R</b> has positive diagonal elements, you can reconstruct the <b>LDU</b> decomposition and see that the pivots are positive (the squares of the diagonal elements in your <b>R</b>). So can conclude that iff some matrix <b>A</b> is <b>positive definite</b> it has a <b>Cholesky decomposition</b>.
</p>

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-cholesky-decomposition</span> (matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Take the output of the LU-decomposition and generate the Cholesky decomposition matrices"</span>
  (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">sqrt-data-elements</span> (data<span style="color: #999999;">)</span>
    <span style="color: #036A07;">"Takes a data vector and squares every element and returns the list"</span>
    (<span style="color: #0000FF;">cond</span> ((null data) '(<span style="color: #999999;">))</span>
          (t
           (cons
            (sqrt (car data<span style="color: #999999;">))</span>
            (sqrt-data-elements (cdr data<span style="color: #999999;">))))))</span>

  (<span style="color: #0000FF;">let*</span> ((LDU (matrix-LDU-decomposition matrix<span style="color: #999999;">))</span>
         (L (first LDU<span style="color: #999999;">))</span>
         (D (second LDU<span style="color: #999999;">))</span>
         (D_sqrt (matrix-from-data-list
                  (matrix-rows D<span style="color: #999999;">)</span>
                  (matrix-rows D<span style="color: #999999;">)</span>
                  (sqrt-data-elements (matrix-data D<span style="color: #999999;">)))))</span>
    (matrix-product L D_sqrt<span style="color: #999999;">)))</span>

</pre>
</div>
<blockquote>
<p>
<b>TODO:</b> The permutation matrix <b>P</b> has disappeared from my proof and from the textbook! You can't do partial pivoting b/c <b>PA</b> is no longer symmetric so everything falls apart. (Still <b>A = A<sup>T</sup></b> ,but when you transpose <b>PA=PLDU</b> you can <b>A<sup>T</sup>P<sup>T</sup>=U<sup>T</sup>DL<sup>T</sup>P<sup>T</sup></b> and there is no equality to proceeed with) You could however do <b>PAP</b>, but if you do it manually you'll see that the pivot position doesn't move and in any case <b>P&ne;P<sup>T</sup></b> so you have the same problem again. I don't understand why we can be sure <b>A</b> needs no pivot adjustments. My searches have confirmed that positive definite matrices do not need permutation matrices to be decomposed - but I don't have a clean explanation
</p>

<p>
see: <a href="https://math.stackexchange.com/questions/621045/why-does-cholesky-decomposition-exist">https://math.stackexchange.com/questions/621045/why-does-cholesky-decomposition-exist</a>#
</p>
</blockquote>
</div>
</div>
<div id="outline-container-org1cf4f2d" class="outline-4">
<h4 id="org1cf4f2d">Solving for A<sup>-1</sup></h4>
<div class="outline-text-4" id="text-org1cf4f2d">
<p>
On <i>page 148</i> we get a simple algorithm for efficiently contructing <b>A<sup>-1</sup></b>. Basically we are taking the equation <b>AA<sup>-1</sup>=I</b>, where <b>A<sup>-1</sup></b> is unknown, and solving it column by column. Treating each column of <b>A<sup>-1</sup></b> as <b>x</b> and each column of <b>I</b> and <b>b</b> we are reusing <b>Ax=b</b> and writing it as <b>AA<sup>-1</sup><sub>*j</sub>=e<sub>j</sub></b>. Once we solve each column we put them all together and rebuild <b>A<sup>-1</sup></b>.
</p>

<p>
Because our data is arranged row-by-row, it'll be easier for me to just build <b>(A<sup>-1</sup>)<sup>T</sup>)</b> and then transpose it back to <b>A<sup>-1</sup></b> at the end.
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-inverse</span> (matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"template"</span>
  (<span style="color: #0000FF;">let</span> ((PLU (matrix-PLU-decomposition matrix<span style="color: #999999;">)))</span>
    (<span style="color: #0000FF;">let*</span>((rank (matrix-rows matrix<span style="color: #999999;">))</span>
          (identity (matrix-identity rank<span style="color: #999999;">)))</span>
    (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-inverse-transpose-rec</span> (column<span style="color: #999999;">)</span>
      <span style="color: #036A07;">"Computer the transpose of the inverse, appending row after row"</span>
      (<span style="color: #0000FF;">cond</span> ((equal column rank<span style="color: #999999;">)</span>
            '(<span style="color: #999999;">))</span>
            (t
             (matrix-append
              (matrix-transpose (matrix-solve-for-input PLU (matrix-get-column identity column<span style="color: #999999;">)))</span>
              (matrix-inverse-transpose-rec (1+ column<span style="color: #999999;">))))))</span>

    (matrix-transpose(matrix-inverse-transpose-rec 0<span style="color: #999999;">)))))</span>
</pre>
</div>
<blockquote>
<p>
<b>TODO:</b> This could be rewritten to be tail recursive
</p>
</blockquote>
</div>
</div>
<div id="outline-container-org408683b" class="outline-4">
<h4 id="org408683b">Least Squares</h4>
<div class="outline-text-4" id="text-org408683b">
<p>
Now that we have a mechanism to solve square linear systems we need to extend <b>Ax=b</b> to the overdefined case where we have more linear equations than parameters. This situation will come up constantly, generally in situations where you only have a few inputs you want to solve for, but you have a lot of redundant measurements. 
</p>

\begin{equation}
\begin{bmatrix}
a_11 & a_12\\
a_21 & a_22\\
a_31 & a_32\\
a_41 & a_42\\
...\\
\end{bmatrix}
\begin{bmatrix}
x_1\\
x_2\\
\end{bmatrix}
=
\begin{bmatrix}
y_1\\
y_2\\
\\
\end{bmatrix}
\end{equation}


<p>
If the measurements were ideal then the rows of <b>A</b> will not be independent and you will be able to find an explicit solution though Gaussian Elimination. But in the general case (with the addition of noise and rounding erros) no explicit solution will exist for <b>A<sub>skinny</sub>x=b</b> so banking on the ideal simply won't work . You could try to find a set of independent equations and throw away the extra equation to try to make a square matrix, but this is throwing information away. If the noise is non-negligible then you actually want all the measurements to build up an average "best fit" solution
</p>

<p>
But if there is no <code>x</code> for which <b>A<sub>skinny</sub>x=b</b> then what can we do? We solve for a close system <b>A<sub>skinny</sub>x=b<sub>close</sub></b> which does have a solution. In other words we want to find an <code>x</code> that will give us a <b>b<sub>close</sub></b> which is as close as possible to <b>b</b>. We want to minimize the sum of the difference between <b>b<sub>close</sub></b> and <b>b</b> - ie. <b>sum<sub>of</sub><sub>all</sub><sub>values</sub>(b<sub>close</sub>-b)</b>.
</p>

<p>
However this is kinda ugly.. and we haven't really found a convenient way to work with sums. Fortunately we do have a mechanism which is really close - the <b>inner product</b>. The inner product of a vector <b>x</b> with itself - <b>x<sup>T</sup>x</b> - is the sum of the squares of the values of <b>x</b>. Furthermore squaring the numbers doesn't change the solution and the minimum stays the minimum. So instead of  <b>sum<sub>of</sub><sub>all</sub><sub>values</sub>(b<sub>close</sub>-b)</b>. we will work with <b>(b<sub>close</sub>-b)<sup>T</sup>(b<sub>close</sub>-b)</b>
</p>

<p>
If we plug in our equation for <code>x</code> for we get <b>(A<sub>skinny</sub>x-b)<sup>T</sup>(A<sub>skinny</sub>x-b)</b>. 
</p>

\begin{equation}
(A_{skinny}x-b)^{T}(A_{skinny}x-b) \\
((A_{skinny}x)^{T}-b^{T})(A_{skinny}x-b) \\
(x^{T}A_{skinny}^{T}-b^{T})(A_{skinny}x-b) \\
x^{T}A_{skinny}^{T}A_{skinny}x
-x^{T}A_{skinny}^{T}b
-b^{T}A_{skinny}x
+b^2
\end{equation}


<p>
As we learn in calculus, minimizing a function is done by take its derivative with respect to the parameter we are changing (here that's <code>x</code>), setting it equal to zero and then solving for that parameter (b/c the minimum point has zero slope). What <i>page 226-227</i> shows is that the derivative of our difference equation give us the equation <b>A<sup>T</sup>Ax=A<sup>T</sup>b</b>. The right hand side <b>A<sup>T</sup>b</b> is a vector, and in-fact the whole equation is in the form <b>Ax=b</b> which we know how to solve (again, solving for <code>x</code> here). Also note that <b>A<sup>T</sup>A</b> is always square and singlular - and that b/c <b>A</b> was skinny it's actually smaller than <b>A</b>.
</p>
</div>

<ul class="org-ul">
<li><a id="org6fe315b"></a>Numerically stable solution<br>
<div class="outline-text-5" id="text-org6fe315b">
<p>
Unfortunately while the solutions turned out in the end to be very clean, it does involve a matrix multiplication and therefore has some numerical issues. A better solution is presented in <b>Exercise 4.6.9</b> with the equations
</p>

\begin{equation}
\begin{bmatrix}
I_{m*m} & A\\
A^T & 0_{n*n}\\
\end{bmatrix}
\begin{bmatrix}
x_1\\
x_2\\
\end{bmatrix}
=
\begin{bmatrix}
b\\
0\\
\end{bmatrix}
\end{equation}

<p>
If you multiply out the block matrices you will get two equation and you will see that <b>x<sub>2</sub></b> is equal to the least squares solution. (<i>Note:</i> crucially the second equation tells you that <b>x<sub>1</sub></b> is in the <b>N(A<sup>T</sup>)</b>)
</p>

<p>
I even double checked that this is true in a <a href="../asparapiss/">little demo program</a> written in Clojure. Fitting a polynomial over some random points the <b>A<sup>T</sup>Ax=A<sup>T</sup>b</b> solution (light blue) quickly gives a broken result as the number of polynomial factors is increased. While the "stable solution" (dark blue) blows up much later.
</p>


<div class="figure">
<p><img src="stable-least-squares.png" alt="stable-least-squares.png">
</p>
</div>
<p>
*
</p>
</div>
</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgac4879f" class="outline-2">
<h2 id="orgac4879f">The QR Decomposition</h2>
<div class="outline-text-2" id="text-orgac4879f">
<p>
The 70 or so pages that follow the "Least Squares" section in the book are rather frustrating b/c there is no end goal in sight, but on paged <i>307-308</i> we have our big reveal. The goal is to construct a new decomposition <b>A=QR</b> that will give us similar benefits to the LU while presenting us with a few more useful properties. It will combine the benefits of lower/upper triangular matrices which gave us forward/back-substitution and the benefits of an orthonormal basis.
</p>

<p>
An <i>orthonormal</i> matrices have a very useful property that its inverse is its transpose <b>Q<sup>T</sup>=Q<sup>-1</sup></b>. This is because each column/row of the matrix is of unit length and orthogonal to the other columns. So when you write out <b>Q<sup>T</sup>Q</b> you see that 
</p>

<ul class="org-ul">
<li>the diagonal elements are the inner products of the columns - and b/c of their unit length it's always equal to 1</li>
<li>the off-diagonal elements involve inner products of orthogonal columns and therefore are equal to 0.</li>
</ul>

<p>
If <b>A</b> is square then the columns of <b>A</b> are already technically in an orthonormal basis, the standard basis (<b>I<sup>T</sup>I=I</b>), where <b>A=IA</b> but obviously that's not very useful. The goal is have the second matrix be something a bit nicer and triangular like in the <b>LU</b> decomposition. We also would like something that generalizes to more than the square case.
</p>
</div>

<div id="outline-container-org29c6c30" class="outline-3">
<h3 id="org29c6c30">The Gram-Schmidt procedure</h3>
<div class="outline-text-3" id="text-org29c6c30">
<p>
The Gram-Schmidt procedure is a recursive algorithm for taking a set of linearly independent vectors (in the standard basis) and rewriting it as a set of coordinates in a new orthonormal basis that will span the same space. The new basis will naturally be in the same space <b>R<sup>n</sup></b> and its dimension will equal the number of indepenent vectors. So given <b>n</b> linearly independent vectors it will return to you a set of <b>n</b> orthonormal vectors that span the same space.
</p>

<p>
This already at face value seems like something that could prove to be useful. After describing the algorithm we will see how we can use these properties to build up the decomposition we want.
</p>
</div>
<div id="outline-container-org6856f62" class="outline-4">
<h4 id="org6856f62">The Base case</h4>
<div class="outline-text-4" id="text-org6856f62">
<p>
We will see that the procedure builds the new basis incrementally one basis vector at a time. And that if we've built a basis for <b>n</b> independent vectors, then adding an <b>n+1</b>'th vector will be very easy. So first we look at the simplest case of just one vector (that's.. independent b/c it's just all alone). To make an orthonormal basis for one vector you just normalizes it. Bare in mind that both the vector and the new basis span the same space
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">
(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-column-2-norm-squared</span> (column<span style="color: #999999;">)</span>
   <span style="color: #036A07;">"get the inner product of a column with itself to get its 2-norm"</span>
   (matrix-inner-product (matrix-transpose column) column<span style="color: #999999;">))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-column-2-norm</span> (column<span style="color: #999999;">)</span>
   <span style="color: #036A07;">"get the 2-norm of a column-vector"</span>
   (sqrt (matrix-column-2-norm-squared column<span style="color: #999999;">)))</span>

 (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-normalize-column</span> (column<span style="color: #999999;">)</span>
   <span style="color: #036A07;">"takes a column and returns a normalized copy"</span>
     (matrix-scalar-product
      column
      (/ 1.0 (matrix-column-2-norm column<span style="color: #999999;">))))</span>


 (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-row-2-norm-squared</span> (row<span style="color: #999999;">)</span>
   <span style="color: #036A07;">"takes the inner product of a column with itself to get its 2-norm"</span>
   (matrix-inner-product row (matrix-transpose row<span style="color: #999999;">)))</span>

 (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-row-2-norm</span> (row<span style="color: #999999;">)</span>
   <span style="color: #036A07;">"get the 2-norm of a column-vector"</span>
   (sqrt (matrix-row-2-norm-squared row<span style="color: #999999;">)))</span>

 (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-normalize-row</span> (row<span style="color: #999999;">)</span>
   <span style="color: #036A07;">"takes a column and returns a normalized copy"</span>
     (matrix-scalar-product
      row
      (/ 1.0 (matrix-row-2-norm row<span style="color: #999999;">))))</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org5c210e7" class="outline-4">
<h4 id="org5c210e7">Recursive Step</h4>
<div class="outline-text-4" id="text-org5c210e7">
<p>
The recursive step describes how to expand your basis when you're given a new independent vector - ie. one that's not in its span - so that the new basis includes this vector. I think it's not immediately obvious, but this will always involve adding just one additional vector to the basis
</p>

<blockquote>
<p>
<b>Example</b>: If you have a basis vector [1 0 0 0 0 0] and you're given a new vector [3 6 7 2 5 8]. The span of the two will actually just be some 2-D hyperplane and you just need one extra orthonormal vector for the new basis to cover it.
</p>
</blockquote>

<p>
And here we get to the meat of the Gram-Schmidt procedure. The fact that it's not in the span of our existing basis means it has two components, one that is in the span and one that is orthogonal to the other basis vectors. (the only corner case is if it's orthogonal already)
</p>

\begin{equation}
x_{k+1}=x_{k+1,orthogonal}+x_{k+1,in-span}
\end{equation}

<p>
Visually you can picture any vector coming out of a plane has a component in the plane and a component perpendicular to the plane. The orthogonal part is what we want to use for our new basis vector.
</p>

\begin{equation}
x_{k+1,orthogonal}=x_{k+1} - x_{k+1,in-span}
\end{equation}

<p>
The part in the span can be constructed by using the inner product to project our new vector <b>x<sub>k+1</sub></b> onto all of our basis vectors <b>q<sub>1</sub></b>, <b>q<sub>2</sub></b>, <b>q<sub>3</sub></b>, <b>&#x2026;</b>. The projections are coordinates in the new basis and they are scalar values, so we multiply them times their respective basis vectors and add them up to get the in-span vector
</p>

\begin{equation}
x_{k+1,in-span}=(q_{1}^{T}x_{k+1})q_{1} + (q_{2}^{T}x_{k+1})q_{2} + .. + (q_{k}^{T}x_{k+1})q_{k}
\end{equation}

<p>
In matrix form we stick the basis vectors into a matrix
</p>
\begin{equation}
Q_k=
\begin{bmatrix}
q_1 & | & q_2 & | & q_3 & .. & q_k \\
\end{bmatrix}
\end{equation}

<p>
Then we can write a column-matrix multiplication to get the coordinates/projections
</p>

\begin{equation}
\begin{bmatrix}
c_{1} \\
c_{2} \\
c_{3} \\
.. \\
c_{k} \\

\end{bmatrix}
 =
\begin{bmatrix}
-- q_1^{T} -- \\
-- q_2^{T} -- \\
-- q_3^{T} -- \\
... \\
-- q_k^{T} -- \\
\end{bmatrix}
\begin{bmatrix}
| \\
x_{k+1} \\
| \\
\end{bmatrix}
\end{equation}

<p>
And finally with the coordinates and the basis vectors we can  build the <i>in-span</i> vector (this is equivalent to the equation)
</p>
\begin{equation}
x_{k+1,in-span}=
\begin{bmatrix}
q_1 & | & q_2 & | & q_3 & .. & q_k \\
\end{bmatrix}
\begin{bmatrix}
c_{1} \\
c_{2} \\
c_{3} \\
.. \\
c_{k} \\
\end{bmatrix}
\end{equation}

\begin{equation}
x_{k+1,in-span}=
\begin{bmatrix}
q_1 & | & q_2 & | & q_3 & .. & q_k \\
\end{bmatrix}
\begin{bmatrix}
-- q_1^{T} -- \\
-- q_2^{T} -- \\
-- q_3^{T} -- \\
... \\
-- q_k^{T} -- \\
\end{bmatrix}
\begin{bmatrix}
| \\
x_{k+1} \\
| \\
\end{bmatrix}
\end{equation}

\begin{equation}
x_{k+1,in-span}=
Q_k Q_k^{T} x_{k+1}
\end{equation}

<p>
And then we can also plug it into the previous equation for the orthogonal component.
</p>
\begin{equation}
x_{k+1,orthogonal}=x_{k+1} - Q_k Q_k^{T} x_{k+1}
\end{equation}
<p>
The code follows the same procedure
</p>
<blockquote>
<p>
<b>Note</b>: Because I've implemented matrices in <a href="https://en.wikipedia.org/wiki/Row-_and_column-major_order">row-major order</a> and because each time we make a new orthogonal basis we want to append it to our existing list - the matrix <b>Q</b> will be treated as <b>Q<sup>T</sup></b> in code
</p>
</blockquote>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-get-orthogonal-component</span> (matrix-of-orthonormal-rows linearly-independent-vector <span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Given matrix of orthonormal rows and a vector that is linearly independent of them - get its orthogonal component"</span>
  (<span style="color: #0000FF;">let*</span> ((QT matrix-of-orthonormal-rows<span style="color: #999999;">)</span>
        (Q (matrix-transpose QT<span style="color: #999999;">))</span>
        (in-span-coordinates (matrix-product QT linearly-independent-vector<span style="color: #999999;">))</span>
        (in-span-vector (matrix-product Q in-span-coordinates<span style="color: #999999;">)))</span>
    (matrix-subtract linearly-independent-vector in-span-vector<span style="color: #999999;">)))</span>
</pre>
</div>

<p>
In the textbook they pull out the vector and write it as:
</p>
\begin{equation}
x_{k+1,orthogonal}=(I - Q_k Q_k^{T}) x_{k+1}
\end{equation}

<p>
But the result is the same. With the orthogonal piece we can finally get the new basis vector by just normalizing it
</p>
\begin{equation}
q_{k+1} = x_{k+1,orthogonal}/||x_{k+1,orthogonal}||
\end{equation}
\begin{equation}
q_{k+1} = (I - Q_k Q_k^{T}) x_{k+1}/||(I - Q_k Q_k^{T}) x_{k+1}||
\end{equation}

<p>
In code it's just a matter of running <code>(matrix-normalize-column ...)</code>.
</p>
</div>
</div>
</div>
<div id="outline-container-org1199b59" class="outline-3">
<h3 id="org1199b59">Decomposing</h3>
<div class="outline-text-3" id="text-org1199b59">
<p>
So now we have a procedure to build an orthonormal basis <b>Q</b> from linearly independent vectors, but we still need to do the last step of turning this into a decompositon similar in form to <b>A=LU</b> - where given a matrix <b>A</b> we can write it as the product of several other matrices
</p>

<p>
A condition of the method (just like with the <b>LU</b>) is that <b>A</b> must be non-singular. That way we can ensure that the columns of <b>A</b> will be linearly independent. The Gram-Schmidt procedure tell us two things: 
</p>
<ul class="org-ul">
<li>How to add a new basis vector to a basis using a new vector not in its span</li>
<li>The basis for one vector on its own</li>
</ul>

<p>
Now to get the orthonormal basis of the columns of <b>A</b>, ie. <b>A<sub>1..n</sub></b> we want to think of it as: add the column <b>A<sub>n</sub></b> to the orthonormal basis of <b>A{1..n-1}</b>. Then think of the orthogonal basis of <b>A{1..n-1}</b> as really the column <b>A<sub>n-1</sub></b> added to the orthogonal basis of <b>A{1..n-2}</b> and so on.. till you get to the orthonormal basis of <b>A{1}</b> which we know how to do.
</p>

<blockquote>
<p>
<b>Note</b>: If the matrix is huge this way of computing will blow the stack. It's more efficient to first <b>A{1}</b> and then appending basis vectors, but the result is less elegant b/c you need to keep track of indeces. The way presented here reuses the code cleanly b/c the procedure on <b>A<sub>n</sub></b> is just the procedure on <b>A<sub>n-1</sub></b> + some extra work. The algorithm itself breaks down the problem into it's smaller parts.
</p>

<p>
<b>Note2</b>: Again, everything is transposed for convenience.. which is not very ergonomic. If I were to start over I'd write it in column major order.
</p>
</blockquote>

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-gram-schmidt</span> (A-transpose<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"For a column return it's normalized basis. For a matrix adds a new orthonormal vector to the orthonormal basis of A_{n-1}"</span>
  (<span style="color: #0000FF;">cond</span> ((= 1 (matrix-rows A-transpose)) <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">base case</span>
         (matrix-normalize-row A-transpose<span style="color: #999999;">))</span>
        (t <span style="color: #8D8D84;">;;</span><span style="color: #8D8D84; font-style: italic;">recursive case</span>
         (<span style="color: #0000FF;">let*</span> ((basis (matrix-gram-schmidt
                        (matrix-submatrix A-transpose 
                                          0
                                          0
                                          (- (matrix-rows A-transpose) 1<span style="color: #999999;">)</span>
                                          (matrix-columns A-transpose<span style="color: #999999;">))))</span>
                (next-column (matrix-transpose
                                        (matrix-get-row A-transpose
                                                        (1- (matrix-rows A-transpose<span style="color: #999999;">)))))</span>
                (orthogonal-component (matrix-get-orthogonal-component basis
                                                                       next-column<span style="color: #999999;">)))</span>
           (matrix-append basis (matrix-transpose (matrix-normalize-column orthogonal-component<span style="color: #999999;">)))))))</span>
</pre>
</div>


<p>
So the function above gives us the orthonormal basis <b>Q</b>, but how do we express <b>A</b> in the term <b>Q</b>? We just look at the equations we've used and work backwards. We start again with breaking up the linearaly independent columns of <b>A</b> into their orthogonal components and their component in the span of the previous <b>k</b> columns
</p>

\begin{equation}
x_{k+1}=x_{k+1,orthogonal}+x_{k+1,in-span}
\end{equation}

<p>
Now this time we want to express everything in terms of the columns of <b>Q</b> and <b>A</b>. We already know <i>x<sub>k+1,in-span</sub></i> is the projections of <i>x<sub>k+1</sub></i> onto the q<sub>1 .. k</sub> vectors - so nothing new there. But we now we want to rewrite the <i>x<sub>k+1,orthogonal</sub></i> in terms of the columns of <b>Q</b> instead of the awkward intermediate <b>Q<sub>k</sub></b> matrices we used during the procedure. Remember during the recursive step we found the orthogonal component using the following formula:
</p>

\begin{equation}
x_{k+1,orthogonal}=(I - Q_k Q_k^{T}) x_{k+1}
\end{equation}

<p>
And then we normalized it to get <i>q<sub>k+1</sub></i>:
</p>

\begin{equation}
q_{k+1} = (I - Q_k Q_k^{T}) x_{k+1}/||(I - Q_k Q_k^{T}) x_{k+1}||
\end{equation}

<p>
So combining the two:
</p>

\begin{equation}
q_{k+1} = x_{k+1,orthogonal}/||(I - Q_k Q_k^{T}) x_{k+1}||
\end{equation}

\begin{equation}
x_{k+1,orthogonal}= ||(I - Q_k Q_k^{T}) x_{k+1}|| q_{k+1}
\end{equation}

<p>
So the full equation for a column of <b>A</b> in terms of the columns of <b>Q</b> becomes:
</p>

\begin{equation}
x_{k+1}=x_{k+1,orthogonal}+x_{k+1,in-span}
\end{equation}
\begin{equation}
x_{k+1}= ||(I - Q_k Q_k^{T}) x_{k+1}|| q_{k+1}  + (q_{1}^{T}x_{k+1})q_{1} + (q_{2}^{T}x_{k+1})q_{2} + .. + (q_{k}^{T}x_{k+1})q_{k}
\end{equation}

<p>
And in matrix form this give us the decomposition <b>QR</b> where:
</p>

\begin{equation}
R=
\begin{bmatrix}
||(I - Q_1 Q_1^{T}) x_1 || && q_1^T x_2 && q_1^T x_3 && ... \\
0 && ||(I - Q_2 Q_2^{T}) x_2 || && q_2^T x_3 && ... \\
0 && 0 && || (I - Q_3 Q_3^{T}) x_2 || &&  ... \\
... && ... && ... \\
\end{bmatrix}
\end{equation}

<p>
The diagonal values are just scalars, but they still remain rather awkward. However, the key thing to recognize is that all these values are just by-products of building the orthonormal basis <b>Q</b>. So if we build <b>R</b> as we go through the Gram-Schmidt procedure and build <b>Q</b> we have no extra work to do!
</p>

<blockquote>
<p>
<b>Note</b>: The following code works but is uglier and longer than it should be. It definitely shouldn't need rec and non-rec functions. 
</p>

<ul class="org-ul">
<li>First, you would normally you would just build up <b>R</b> for the <b>A<sub>n-1</sub></b> case and then appending a row of zeroes and then appending the next column at each iteration - each iteration indepedent of each other (without passing the rediculous "dimension" variable)</li>
<li>Second this would be a lot simpler if matrices were in column major order. The QR-rec function has to work on the transposes of matrices and it's very awkward</li>
</ul>
</blockquote>

<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-build-R-column-rec</span> (QT next-linearly-independent-vector norm-factor dimension<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Builds the data vector for a column of R"</span>
  (<span style="color: #0000FF;">cond</span> ((= 0 dimension) <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">finished building column</span>
         '(<span style="color: #999999;">))</span>

        ((&lt; (matrix-rows QT) dimension) <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">add bottom zeroes</span>
         (cons
          9.0
          (matrix-build-R-column-rec QT next-linearly-independent-vector norm-factor (1- dimension<span style="color: #999999;">))))</span>

        (( = (matrix-rows QT) dimension) <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">add orthogonal part</span>
         (cons
          norm-factor
          (matrix-build-R-column-rec QT next-linearly-independent-vector norm-factor (1- dimension<span style="color: #999999;">))))</span>

        ((&gt; (matrix-rows QT) dimension) <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">add in-span part</span>
         (cons
          (matrix-get-value (matrix-product
                             (matrix-get-row QT dimension<span style="color: #999999;">)</span>
                             next-linearly-independent-vector<span style="color: #999999;">)</span>
                            0
                            0<span style="color: #999999;">)</span>
          (matrix-build-R-column-rec Q next-linearly-independent-vector norm-factor (1- dimension<span style="color: #999999;">))))))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-build-R-column</span> (Q next-linearly-independent-vector norm-factor dimension<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Returns a column vector for the new column of R"</span>
  (matrix-from-data-list dimension 1  (reverse (matrix-build-R-column-rec Q next-linearly-independent-vector norm-factor dimension<span style="color: #999999;">))))</span>


(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-QR-decomposition-rec</span> (A-transpose dimension) <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">'dimension' keeps track of the ultimate size of R</span>
  <span style="color: #036A07;">"The recursive helper function that builds up the Q and R matrices"</span>
  (<span style="color: #0000FF;">cond</span> ((= 1 (matrix-rows A-transpose)) <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">base case</span>
         (list
          (matrix-normalize-row A-transpose) <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">starting Q "matrix"</span>
          (matrix-scalar-product (matrix-unit-row 0 dimension) <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">starting R "matrix"</span>
                                 (matrix-row-2-norm-squared A-transpose<span style="color: #999999;">))))</span>
        (t <span style="color: #8D8D84;">;;</span><span style="color: #8D8D84; font-style: italic;">recursive case</span>
         (<span style="color: #0000FF;">let*</span> ((QTRT (matrix-QR-decomposition-rec
                       (matrix-submatrix A-transpose
                                         0
                                         0
                                         (- (matrix-rows A-transpose) 1<span style="color: #999999;">)</span>
                                         (matrix-columns A-transpose<span style="color: #999999;">))</span>
                       dimension<span style="color: #999999;">))</span>
                (basis (first QTRT<span style="color: #999999;">))</span>
                (RT (second QTRT<span style="color: #999999;">))</span>
                (next-column (matrix-transpose
                              (matrix-get-row A-transpose
                                              (1- (matrix-rows A-transpose<span style="color: #999999;">)))))</span>
                (orthogonal-component (matrix-get-orthogonal-component basis
                                                                       next-column<span style="color: #999999;">))</span>
                (new-basis (matrix-append basis
                                          (matrix-transpose (matrix-normalize-column orthogonal-component<span style="color: #999999;">))))</span>
                (new-RT (matrix-append RT
                                       (matrix-transpose
                                        (matrix-build-R-column
                                         new-basis
                                         next-column
                                         (matrix-row-2-norm-squared orthogonal-component<span style="color: #999999;">)</span>
                                         dimension<span style="color: #999999;">)))))</span>
           (list new-basis new-RT<span style="color: #999999;">)))))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-gramschmidt-QR</span> (A<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Returns a list of the Q and R matrices for A"</span>
  (matrix-QR-decomposition-rec (matrix-transpose A<span style="color: #999999;">)</span>
                               (matrix-columns A<span style="color: #999999;">)))</span>
</pre>
</div>


<p>
#+END<sub>SRC</sub>
</p>

<p>
We just need to rewrite this in term of our new
is in effect doing what we did in the recursive step, but backwards
</p>
</div>
</div>
<div id="outline-container-orgceabc14" class="outline-3">
<h3 id="orgceabc14">The Householder reduction</h3>
<div class="outline-text-3" id="text-orgceabc14">
<p>
An alternate method to build a <b>QR</b> matrix is to take a more direct approach like in the <b>LU</b> and to zero out columns to build an upper triangular <b>R</b>. The difference from the <b>LU</b> is that now instead of using row operations to get zeroes we will restrict ourselves to using <b>elementary reflectors</b>. Their key property is that they are orthonormal, so when we carry out a series of reflections <b>Q<sub>1</sub>Q<sub>2</sub>..Q<sub>k</sub>A</b> we can combine them into one matrix which will be guaranteed to be orthonormal too. In the <b>LU</b>'s Gaussian elimination the elementary matrices we used were not  orthonormal so we didn't have this same guarantee (for a simple example consider row-addition: it's not orthogonal and its norm isn't equal to 1)
</p>
</div>

<div id="outline-container-orgef043d8" class="outline-4">
<h4 id="orgef043d8">elementary reflector</h4>
<div class="outline-text-4" id="text-orgef043d8">
<p>
An elementary reflector is a special matrix/linear-system which when given a vector produces its reflection across a hyperplane. The hyperplane is orthogonal to some reference vector <b>u</b>. The textbook has a nice illustration for the <b>R<sup>3</sup></b> case , but to understand it in higher dimensions you need to break up the problem. The hyperplane you reflect over is the <i>not-in-span-of</i> <b>u</b> space. So in effect to get the reflection you are taking the component of your vector that's in the direction of <b>u</b> and subtracting it twice to create its reflection. If the input vector is <b>x</b> then:
</p>
<ul class="org-ul">
<li><b>u<sup>t</sup>x</b> is the amount of <b>x</b> in the direction of <b>u</b> (a scalar)</li>
<li><b>uu<sup>t</sup>x</b> is the vector component in the direction of <b>u</b> (a vector)</li>
<li><b>uu<sup>t</sup>x/u<sup>t</sup>u</b> is the same vector normalized (a vector)</li>
<li><b>x - 2uu<sup>t</sup>x/u<sup>t</sup>u</b> is you subtracting that vector component twice to get the reflection</li>
</ul>
<p>
In matrix form we'd factor out the <b>x</b> and get <b>(I-2uu<sup>t</sup>/u<sup>t</sup>u)x</b>
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-elementary-reflector</span> (column-vector<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Build a matrix that will reflect vector across the hyperplane orthogonal to COLUMN-VECTOR"</span>
  (<span style="color: #0000FF;">let</span> ((dimension (matrix-rows column-vector<span style="color: #999999;">)))</span>
    (matrix-subtract (matrix-identity dimension<span style="color: #999999;">)</span>
                     (matrix-scalar-product (matrix-product column-vector (matrix-transpose column-vector<span style="color: #999999;">))</span>
                                            (/ 2 (matrix-column-2-norm-squared column-vector<span style="color: #999999;">))))))</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-orge3a18b0" class="outline-4">
<h4 id="orge3a18b0">elementary coordinate reflector</h4>
<div class="outline-text-4" id="text-orge3a18b0">
<p>
To build an upper triangular matrix we need to zero out values below the diagonal. The way we're going to do is by reflecting those columns onto coordinate axis. Ocne a vector is on a coordinate axis then its other components are naturally zero!
</p>

<p>
So now we would like to take this idea of the reflector matrix a bit further and find a way to construct one that will reflect the input vector straight on to a particular coordinate axis. So it needs to have an orthogonal hyperplane that's right between the vector and coordinate axis. This part is a bit hard to picture, but the equation for the vector orthogonal to the reflection plane is
</p>
\begin{equation}
u = x + sign(x_{1})||x||e_{1}
\end{equation}
<p>
Here <b>x</b> is our vector and <b>e<sub>1</sub></b> is the coordinate axis onto which we want to reflect. <b>sign(x)||x||e<sub>1</sub></b> is a vector on the coordinate axis that's stretched out so that it forms a sort of isosceles triangle with <b>x</b> (in higher dimension&#x2026;). Since we want the result to lie on <b>e<sub>1</sub></b> we want to reflect <b>x</b> on the line/hyperplane bisecting this triangle. The bisecting line of a isosceles triangle is perpendicular to its base - so it's perfect for our <b>u</b>! And it so happens that the the equation for the base is the equation we have
</p>

<blockquote>
<p>
The <code>sign(x_{1})</code> is a bit confusion for me to think about&#x2026; If you stick to <b>u = x - ||x||e<sub>1</sub></b> it should be more clear. <b>TODO</b> ..  revisit this
</p>
</blockquote>

<p>
So given a vector and a coordinate axis we can quickly build this on top of our previous function. We just need to add a little catch for the case where the vector is already on axis (then it's ofcourse simply the identity matrix!)
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">sign</span> (number<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"returns 1 if positive or zero and -1 if negative.. Cant' find an ELisp function that does this"</span>
  (<span style="color: #0000FF;">cond</span> ((= number 0.0) 1.0<span style="color: #999999;">)</span>
        (t (/ number (abs number<span style="color: #999999;">)))))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-elementary-coordinate-reflector</span> (column-vector coordinate-axis<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Build a matrix that will reflect the COLUMN-VECTOR on to the COORDINATE-AXIS"</span>
  (<span style="color: #0000FF;">let</span> ((vector-orthogonal-to-reflection-plane
        (matrix-subtract column-vector
                         (matrix-scalar-product coordinate-axis
                                                ( * (sign (matrix-get-value column-vector 0 0<span style="color: #999999;">))</span>
                                                    (matrix-column-2-norm column-vector<span style="color: #999999;">))))))</span>
    (<span style="color: #0000FF;">cond</span> (( = 0 ( matrix-column-2-norm vector-orthogonal-to-reflection-plane)) <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">when both vectors are the same</span>
           (matrix-identity (matrix-rows column-vector))) <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">then the reflector is the identity</span>
          (t
           (matrix-elementary-reflector vector-orthogonal-to-reflection-plane<span style="color: #999999;">)))))</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org17c2727" class="outline-4">
<h4 id="org17c2727">The QR decomposition - part 2</h4>
<div class="outline-text-4" id="text-org17c2727">
<p>
So now we can build matrices that reflect vector onto axis. We need to leverage this to build the upper triangluar matrix <b>R</b> of the <b>QR</b>. If we directly start to zero out things column after column with reflectors like we did in the <b>LU</b> case we would get an equation of the form  <b>Q<sub>k</sub>..Q<sub>2</sub>Q<sub>1</sub>A=R</b>. But the problem is that the <b>Q<sub>i</sub></b>'s are not as clean as row operations and the column of zeroes will not get preserved between reflections. In other words <b>Q<sub>1</sub></b> will reflect the first column onto <b>e<sub>1</sub></b>, but then the second reflector <b>Q<sub>2</sub></b> will reflect it away somewhere else and you will lose those zeroes. So we need to be a little more clever here and find a way to preserve these columns as we go forward.
</p>

<p>
<i>p. 341</i> shows how using block matrices we can write <b>Q<sub>2</sub></b> in such a way as to not disrupt the first column (Note that the book chooses to confusingly use the letter <b>R<sub>i</sub></b> where I'm using <b>Q<sub>i</sub></b>)
</p>

\begin{equation}
Q_{2}
=
\begin{bmatrix}
1 & 0\\
0 & S_{ n-1, m-1 }\\
\end{bmatrix}
\end{equation}

<p>
This specially constructed <b>Q<sub>2</sub></b> will leave the first column untouched but will apply <b>S</b> on to a <i>submatrix</i> of <b>Q<sub>1</sub>A</b>. And <b>S</b> is just another reflector matrix, but it's one row/column smaller and it's job will be to  zero out the first column of that submatrix - which will be the <i>second</i> column of <b>A</b>.
</p>

<p>
It's interesting that this also leaves the first row of <b>Q<sub>1</sub>A</b> untouched so there is also a pattern to how <b>R</b> emerges as we apply these special reflectors.
</p>

<p>
On the next page (342) the book generalizes this trick to any dimension and shows you how to build this rest of the <b>Q<sub>i</sub></b> matrices - <b>Do not use this!!</b> There is a much better way!!
</p>

<p>
Here we need to go a step further than the book to expose an elegance they miss. Imagine we had the full <b>QR</b> for the sub-matrix already somehow. In other words we had some smaller matrix <b>Q<sub>s</sub></b> that could triangularize the sub-matrix entirely in one go. Well with the help of the previous formula we can augment <b>Q<sub>s</sub></b>, combine it with our <b>Q<sub>1</sub></b> (b/c it handles the first column of <b>A</b>, the part not in the submatrix) and build our <b>Q</b> directly!
</p>

\begin{equation}
\begin{bmatrix}
Q\\
\end{bmatrix}
=
\begin{bmatrix}
1 & 0\\
0 & Q_{s}\\
\end{bmatrix}
\begin{bmatrix}
Q_{1}\\
\end{bmatrix}
\end{equation}


\begin{equation}
\begin{bmatrix}
1 & 0\\
0 & Q_{s}\\
\end{bmatrix}
\begin{bmatrix}
Q_{1}\\
\end{bmatrix}
\begin{bmatrix}
A\\
\end{bmatrix}
=
\begin{bmatrix}
R\\
\end{bmatrix}
\end{equation}

<p>
But we don't have the <b>QR</b> for this submatrix yet! ie. no <b>Q<sub>s</sub></b>, so to get it we need to start this method over again, but now working on this smaller submatrix. And a method that invokes itself is really just a recursive function! Each time the method calls itself the problem get smaller and the submatrices are one column and row shorter. Once we hit a simple column or row vector the <b>QR</b> decomposition becomes apparent. Then going back up we know how to combine the smaller <b>QR</b> which each steps reflector to build up the finally <b>Q</b> matrix for <b>A</b>.
</p>

<p>
<b>R</b> is built up similarly in parallel
</p>

<blockquote>
<p>
B/c of inadequacies of my matrix format and the minimal array of helper functions this is a bit longer than it really should be.
</p>
</blockquote>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-add-zero-column-data</span> (data-list columns<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Adds a zero column to the front of a matrix data list. Provide the amount of COLUMNS on input"</span>
  (<span style="color: #0000FF;">cond</span> ((not data-list) '(<span style="color: #999999;">))</span>
        (t (append (cons 0.0 (seq-take data-list columns<span style="color: #999999;">))</span>
                   (matrix-add-zero-column-data (seq-subseq data-list columns) columns<span style="color: #999999;">)))))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-raise-rank-Q</span> (matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Adds a row and column of zeroes in at the top left corner. And a one in position 0,0"</span>
  (<span style="color: #0000FF;">let</span> ((rank (matrix-rows matrix))) <span style="color: #8D8D84;">;; </span><span style="color: #8D8D84; font-style: italic;">Q is always square</span>
    (matrix-from-data-list (1+ rank<span style="color: #999999;">)</span>
                           (1+ rank<span style="color: #999999;">)</span>
                           (append (cons 1.0 (make-list rank 0.0<span style="color: #999999;">))</span>
                                   (matrix-add-zero-column-data (matrix-data matrix<span style="color: #999999;">)</span>
                                                                rank<span style="color: #999999;">)))))</span>

(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-build-R</span> (sub-R intermediate-matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Insets SUB-R into INTERMEDIATE-MATRIX so that only the first row and columns are preserved"</span>
  (matrix-from-data-list (matrix-rows intermediate-matrix<span style="color: #999999;">)</span>
                         (matrix-columns intermediate-matrix<span style="color: #999999;">)</span>
                         (append (seq-take (matrix-data intermediate-matrix<span style="color: #999999;">)</span>
                                           (matrix-columns intermediate-matrix<span style="color: #999999;">))</span>
                                 (matrix-add-zero-column-data (matrix-data sub-R<span style="color: #999999;">)</span>
                                                              (matrix-columns sub-R<span style="color: #999999;">)))))</span>


(<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-householder-QR</span> (matrix<span style="color: #999999;">)</span>
  <span style="color: #036A07;">"Use reflection matrices to build the QR matrix"</span>
  (<span style="color: #0000FF;">let*</span> ((reflector-matrix (matrix-elementary-coordinate-reflector (matrix-get-column matrix 0<span style="color: #999999;">)</span>
                                                                   (matrix-unit-column 0 (matrix-rows matrix<span style="color: #999999;">))))</span>
         (intermediate-matrix (matrix-product reflector-matrix
                                              matrix<span style="color: #999999;">)))</span>
    (<span style="color: #0000FF;">cond</span> (( = (matrix-columns matrix) 1<span style="color: #999999;">)</span>
           (list reflector-matrix intermediate-matrix<span style="color: #999999;">))</span>
          (( = (matrix-rows matrix) 1<span style="color: #999999;">)</span>
           (list reflector-matrix intermediate-matrix<span style="color: #999999;">))</span>
          (t
           (<span style="color: #0000FF;">let*</span> ((submatrix (matrix-submatrix intermediate-matrix
                                               1
                                               1
                                               (matrix-rows intermediate-matrix<span style="color: #999999;">)</span>
                                               (matrix-columns intermediate-matrix<span style="color: #999999;">)))</span>
                  (submatrix-QR (matrix-householder-QR submatrix<span style="color: #999999;">)))</span>
             (<span style="color: #0000FF;">let</span> ((sub-Q (first submatrix-QR<span style="color: #999999;">))</span>
                   (sub-R (second submatrix-QR<span style="color: #999999;">)))</span>
               (list (matrix-product (matrix-raise-rank-Q sub-Q<span style="color: #999999;">)</span>
                                     reflector-matrix<span style="color: #999999;">)</span>
                     (matrix-build-R sub-R
                                     intermediate-matrix<span style="color: #999999;">))))))))</span>

<span style="color: #999999;">)</span>
</pre>
</div>
<p>
In some ways this method is nicer than Gram-Schmidt b/c the goal is more direct - to zero out the columns; and the method is very clean and recursive. However the end result is harder to interpret. <b>Q</b> is now a product of reflectors each working on a different dimensions. It's easy to see why it's orthonormal, but what this final product signifies is not as clear as with Gram Schmidt. B/c both methods produce the same result we can use both to glean insight.
</p>
</div>
</div>
</div>
<div id="outline-container-org055e961" class="outline-3">
<h3 id="org055e961">Givens reduction</h3>
<div class="outline-text-3" id="text-org055e961">
<p>
Is similar to the Householder by uses plane rotations instead. These can eliminate value in your matrix one rotation at a time. It can make sense for sparse matrices&#x2026; I will return to this if it turns out crucial.
</p>
</div>
</div>
<div id="outline-container-orgd57424c" class="outline-3">
<h3 id="orgd57424c">Least Squares again</h3>
<div class="outline-text-3" id="text-orgd57424c">
<p>
While the new <b>QR</b> matrices seem to have some very desirable qualities as compared to the <b>LU</b>, one major issue is still outstanding. When we perform Gaussian Elimination the upper and lower triangular matrices directly inform us about how to solve the <b>Ax=b</b> system of linear equations. Given an output <b>b</b> we can use back/forward substitution to pop out an <b>x</b> input that satisfies the system of equations. However with the <b>QR</b> the <b>Q</b> doesn't really make this same method possible b/c it's not triangular.
</p>

<p>
This is where we need to remember the Least Squared method we'd used previously. In short when a precise solution doesn't exist we try to minimize the difference between <b>Ax</b> and <b>b</b> by taking the derivative of <b>(Ax-b)<sup>2</sup></b>, setting it equal to zero and solving the new system. We found that in matrix notation this gave us <b>A<sup>T</sup>Ax=A<sup>T</sup>b</b>. We also say (and it should be intuitively apparent) that this gives the exact solution for <b>Ax=b</b> when it exist. Now sticking <b>QR</b> in for <b>A</b> we get <b>(QR)<sup>T</sup>QRx=(QR)<sup>T</sup>b</b> -&gt; <b>R<sup>T</sup>Q<sup>T</sup>QRx=R<sup>T</sup>Q<sup>T</sup>b</b> and this is where the orthonormality starts to finally pay off! <b>Q<sup>T</sup>=Q<sup>-1</sup></b> so <b>Q{T}Q = I</b> and so our equations just becomes <b>R<sup>T</sup>Rx=R<sup>T</sup>Q<sup>T</sup>b</b> where the right side will evaluate to some some unit column and the left side will be solvable my back/forward substitution again (b/c <b>R</b> and <b>R<sup>T</sup></b> are triangular)
</p>

<p>
Notice that we did that all in theoretical equation form and how we've avoided having to actually compute <b>A<sup>T</sup>A</b> completely which is a big advantage considering getting the <b>QR</b> is more computationally challenging than doing Gaussian Elimination. Pages 346-350 also enumerate the advantages when it comes to numerical stability and computational complexity. However, the augmented matrix trick from <b>Exercise 4.6.9</b> is not mentioned.
</p>
</div>
</div>
</div>
<div id="outline-container-orgc118400" class="outline-2">
<h2 id="orgc118400"><span class="todo TODO">TODO</span> s</h2>
<div class="outline-text-2" id="text-orgc118400">
<ul class="org-ul">
<li>Write a better example that I can expand on easily later</li>
<li>Implement the Sherman-Morrison update formula</li>
<li>Sensitivity/Condition numbers needs to be revisited and expanded on (page 126-128)</li>
<li>Do exercise 3.8.8</li>
<li>Tridiagonal matrices - 3.10.6</li>
</ul>
</div>
</div>
<div id="outline-container-orge85c9c1" class="outline-2">
<h2 id="orge85c9c1">SRC<sub>Block</sub> template</h2>
<div class="outline-text-2" id="text-orge85c9c1">
<div class="org-src-container">
<pre class="src src-emacs-lisp">  (<span style="color: #0000FF;">defun</span> <span style="color: #006699;">matrix-template</span> (matrix<span style="color: #999999;">)</span>
<span style="color: #036A07;">"template"</span>
<span style="color: #999999;">)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org46e7558" class="outline-2">
<h2 id="org46e7558">End</h2>
<div class="outline-text-2" id="text-org46e7558">
<blockquote>
<p>
This webpage is generated from an org-document (at <code>./index.org</code>) that also generates all the files described. 
</p>

<p>
Once opened in Emacs:<br>
</p>
<ul class="org-ul">
<li><code>C-c C-e h h</code> generates the webpage  <br></li>
<li><code>C-c C-v C-t</code> exports the code blocks into the appropriate files<br></li>
<li><code>C-c C-c</code>     org-babel-execute-src-block</li>
<li><code>C-c C-v C-b</code> org-babel-execute-buffer</li>
</ul>
</blockquote>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: George Kontsevich</p>
<p class="date">Created: 2019-07-25 Thu 09:42</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
