#+TITLE: Linear Systems in Lisp
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="https://geokon-gh.github.io/static/worg.css" />
#+options: num:nil
# This will export a README.org file for Github, so that people that land in my repo know where to find the relevant webpage
#+HTML_MATHJAX: path: "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"
#+BEGIN_SRC org :tangle README.org :exports none :eval never
  see description [[http://geokon-gh.github.io/linearsystems/index.html][here]]
#+END_SRC

* Preface
This text is primarily my personal notes on linear algebra as I go through [[matrixanalysis.com][Matrix Analysis & Applied Linear Algebra]]. At the same time this document is a literate program that can be executed in Emacs so the text will be slowly building up a linear algebra library of sorts. This will often not match the order things are presented in the book. There is no emphasis on performance - just on clarity, extensability and correctness when possible. This is purely (self)educational with my primary motivation being to help me better understand what I learn (through having to explain it) and to sanity check with actual programs. Things that are adequately explained in the book will not be repeated here.

This is my first program in Elisp, so if you see any issues, please leave a note in the [[https://github.com/geokon-gh/linearsystems/issues][issues]] tab of [[https://github.com/geokon-gh/linearsystems/][the repository]]. There you can also find the original org-mode file and the generated elisp files - both of which have additional unit-tests ommited from this webpage.

This is very much a work in progress and will change often...

* Systems of linear equations
The book's opening problem from ancient China of calculating the price of bushels of crop serves as a good example of a linear problem. I've simplified the problem a bit for clarity - but I will expand on it and refer back to it extensively:
** A farming problem
#+BEGIN_QUOTE
You have a 3 fruit farms in a region of ancient China. In a given year:

*Given 1:*\\
Farm 1 produces 3 tons of apples 2 ton of  oranges and 1 ton  of lemons\\
Farm 2 produces 2 tons of apples 3 tons of oranges and 1 ton  of lemons\\
Farm 3 produces 1 ton  of apples 2 tons of oranges and 3 tons of lemons\\

*Given 2:*\\
Farm 1 sold its fruit for 39 yuan\\
Farm 2 sold its fruit for 34 yuan\\
Farm 3 sold its fruit for 26 yuan\\

What is the price of the a ton of apples/oranges/lemons?
#+END_QUOTE 
This is a familiar problem that can be restated as a system of linear equations

\begin{equation}
\begin{split}
3x+2y+z = 39\\
2x+3y+z = 34\\
x+ 2y + 3z = 26
\end{split}
\end{equation}

Where ~x~, ~y~ and ~z~ represent ~apples~ ~oranges~ and ~lemons~ respectively

We know how to solve this system by manipulating the equations, solving for a variable and then back-substituting the results.

It's not accident I split up the problem into two sets of *Givens*. It's important to note that the problem actually has two distinct and independent parts. There is the farm/crop *linear system* (~Given 1~), and then there is the *constraint* of the profits of each farm (~Given 2~)

We are looking for the input fruit-prices that will yield the given profits for each farm

* Matices as representations of linear systems
The *linear system* can be represented with a matrix

\begin{bmatrix}
3 & 2 & 1\\
2 & 3 & 1\\
1 & 2 & 3\\
\end{bmatrix}

or flipped::

\begin{bmatrix}
3 & 2 & 1\\
2 & 3 & 2\\
1 & 1 & 3\\
\end{bmatrix}

We prefer the first representation, but both ways work as long as you remember what each row and column represents

** The Matrix in the computer
Once we've chosen a layout the easiest way to store the matrix in the computer is to remember 3 values: ~number-of-rows~ ~number-of-columns~ ~data~

The ~data~ value will be a long list of size ~num-row * num-col~ that contains all the values of the matrix; row after row. So given a list ~data~ and a pair of sizes we simply build the matrix into a list of these three values: 
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-from-data-list (number-of-rows number-of-columns data-list)
    "Builds a matrix from a data list"
    (list 
     number-of-rows 
     number-of-columns 
     data-list))
#+END_SRC
*** Some helpers
With a couple of helper function we can get back these 3 fields. This will improve the readability of the code as we go along
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-rows (matrix)
    "Get the number of rows"
    (nth 0 matrix))
  (defun matrix-columns (matrix)
    "Get the number of columns"
    (nth 1 matrix))
  (defun matrix-data (matrix)
    "Get the data list from the matrix"
    (nth 2 matrix))
  (defun matrix-get-value (matrix row column)
    "Get the scalar value at position ROW COLUMN (ZERO indexed) from MATRIX"
    (nth
     (+
      column
      (*
       row
       (matrix-columns matrix)))
      (matrix-data matrix)))
#+END_SRC
#+BEGIN_QUOTE
~nth~ gets the nth element of the list
#+END_QUOTE
For debugging and looking at results we also need to be able to print out the matrix for inspection
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-data-get-first-n-values (data n)
    "Given a list of values, get the first n in a string"
    (if (zerop n)
        "" ;base case
      (concat
       (number-to-string (car data))
       " "
       (matrix-data-get-first-n-values (cdr data) (1- n))))) ;iterative step

  (defun matrix-data-print (number-of-rows number-of-columns data)
    "Print out the data list gives the dimension of the original matrix"
    (if (zerop number-of-rows)
        "" ;base case
      (concat
       (matrix-data-get-first-n-values data number-of-columns)
       "\n"
       (matrix-data-print ;iterative step
        (1- number-of-rows)
        number-of-columns
        (nthcdr number-of-columns data )))))

  (defun matrix-print (matrix)
    "Print out the matrix"
    (concat "\n" (matrix-data-print
                  (matrix-rows matrix)
                  (matrix-columns matrix)
                  (matrix-data matrix))))
  ; ex:  (message (matrix-print (matrix-from-data-list 2 2 '(1 2 3 4))))
#+END_SRC
#+BEGIN_QUOTE
~zerop~ tests if the value is zero
#+END_QUOTE
#+BEGIN_QUOTE
~()~ with a quote is the /empty-list/ 
#+END_QUOTE
#+BEGIN_QUOTE
~cons~ attaches the first argument to the second argument (which is normally a list)
#+END_QUOTE
#+BEGIN_QUOTE
~cdr~ returns the list without the first element
#+END_QUOTE
** Transposition: Getting the other equivalent matrix
Since we have two equivalent matrices that represent our linear system we need a mechanism to go from one to the other. This method is the matrix transpose which flips the matrix along the diagonal. The text goes into depth on the properties of the matrix transpose, but in short, as long as you take the transpose of both sides of your equations equivalances will be preserved.
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-transpose (matrix)
    "Get the transpose of a matrix"
    (if (equal (matrix-columns matrix) 1)
      (matrix-from-data-list
       1
       (matrix-rows matrix)
       (matrix-data matrix))
      (matrix-append
       (matrix-from-data-list
        1
        (matrix-rows matrix)
        (matrix-data (matrix-get-column matrix 0)))
       (matrix-transpose
        (matrix-submatrix
         matrix
         0
         1
         (matrix-rows matrix)
         (matrix-columns matrix))))))
#+END_SRC
* Representing the whole system of equations
Now that we can represent the fruit/profits system we want a mechanism to represent the whole system of equations so that given a constraint, we can solve for a solution.
** Matrix Multiplication
This is done notationally with matrix multiplication. The notation allows us to keep the two *Givens* separated and allows us to visually chain linear systems together. As a shorthand, we write the product of two matrices ~A~ and ~B~ as ~AB = C~, with the order of ~A~ and ~B~ being important. For every value (at a given row and column position) in the resulting matrix ~C~ we take the equivalent row in ~A~ and multiply it by its equivalent column in ~B~. From this we can conclude that ~C~ will have as many rows as ~A~ and as many column as ~B~

Multiplying a row times a column is called an ~inner product~

*** Inner Product
The ~inner-product~ is defined as the sum of the product of every pair of equivalent elements in the two vectors. The sum will naturally return one scalar value. This operation only makes sense if both the row and column have the same number of values.

#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-inner-product (row column)
    "Multiply a row times a column and returns a scalar"
    (reduce
     '+
     (for-each-pair
      (matrix-data row)
      (matrix-data column)
      '*)))
#+END_SRC
#+BEGIN_QUOTE
~reduce~ works down the list elements-by-element applying the operator on each cumulative result
#+END_QUOTE

*** Submatrices
To get rows and columns (and other submatrices) we need a few more helper functions
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-extract-subrow (matrix row start-column end-column)
    "Get part of a row of a matrix and generate a row matrix from it. START-COLUMN is inclusive,  END-COLUMN is exclusive"
    (let
        ((number-of-columns-on-input (matrix-columns matrix))
         (number-of-columns-on-output (-
                                       end-column 
                                       start-column)))
      (matrix-from-data-list
       1
       number-of-columns-on-output
       (subseq
        (matrix-data matrix)
        (+ (* row number-of-columns-on-input) start-column)
        (+ (* row number-of-columns-on-input) end-column)))))

  (defun matrix-append (matrix1 matrix2)
    "Append one matrix (set of linear equations) to another"
    (if (null matrix2)
        matrix1
      (matrix-from-data-list
       (+
        (matrix-rows matrix2)
        (matrix-rows matrix1))
       (matrix-columns matrix1)
       (append
        (matrix-data matrix1)
        (matrix-data matrix2)))))

  (defun matrix-submatrix (matrix start-row start-column end-row end-column)
    "Get a submatrix. start-row/column are inclusive. end-row/column are exclusive"
    (if (equal start-row end-row)
        '()
      (matrix-append
       (matrix-extract-subrow matrix start-row start-column end-column)
       (matrix-submatrix
        matrix
        (1+ start-row)
        start-column
        end-row
        end-column))))

  (defun matrix-get-row (matrix row)
    "Get a row from a matrix. Index starts are ZERO"
    (matrix-extract-subrow
     matrix
     row
     0
     (matrix-columns matrix)))

  (defun matrix-get-column (matrix column)
    "Get a column from a matrix. Index starts are ZERO"
    (matrix-submatrix
     matrix
     0
     column
     (nth 0 matrix)
     (1+ column)))
#+END_SRC

*** Matrix Product
Now we have all the tools we need to write down the algorithm for calculating the matrix product. First we write a function to calculate the product for one value at a given position

#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-product-one-value (matrix1 matrix2 row column)
    "Calculate one value in the resulting matrix of the product of two matrices"
    (matrix-inner-product
     (matrix-get-row matrix1 row )
     (matrix-get-column matrix2 column)))
#+END_SRC
And then we recursively apply it to construct the resulting matrix
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-product (matrix1 matrix2)
    "Multiply two matrices"

    (defun matrix-product-rec (matrix1 matrix2 row column)
      "A recursive helper function that builds the matrix multiplication's data vector"
      (if (equal (matrix-rows matrix1) row)
          '()
        (if (equal (matrix-columns matrix2) column)
            (matrix-product-rec
             matrix1
             matrix2
             (1+ row)
             0)
          (cons
           (matrix-product-one-value
            matrix1
            matrix2
            row column)
           (matrix-product-rec
            matrix1
            matrix2
            row
            (1+ column))))))

    (matrix-from-data-list
     (matrix-rows matrix1)
     (matrix-columns matrix2)
     (matrix-product-rec
      matrix1
      matrix2
      0
      0)))
#+END_SRC

*** Matrix Conformability
You will notice that the algorithm won't make sense if the number of columns of ~A~ doesn't match the number of rows of ~B~. When the values match the matrices are called *conformable*. When they /don't/ match you will see that inner product isn't defined and therefore neither is the product.
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-conformable? (matrix1 matrix2)
    "Check that two matrices can be multiplied"
    (equal
     (matrix-columns matrix1)
     (matrix-rows matrix2)))
#+END_SRC
*** Addendum: Scalar Product
An additional form of matrix multiplication is between a matrix and a scalar. Here we simply multiply each element of the matrix times the scalar to construct the resulting matrix. The order of multiplication is not important -> *\alpha{}A=A\alpha{}*
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-scalar-product (matrix scalar)
    "Multiple the matrix by a scalar. ie. multiply each value by the scalar"
    (matrix-from-data-list
     (matrix-rows matrix)
     (matrix-columns matrix)
     (mapcar
     (lambda (x) 
       (* scalar x))
     (matrix-data matrix))))
#+END_SRC

** TESTS :noexport:
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (ert-deftest matrix-test-multiplication-and-submatrices ()
    "Testing - Matrix Operations"
    (let ((matrix1 '(2 2 (1 2 3 4)))
          (matrix2 '(2 2 (5 6 7 8))))
    (should (equal
             (matrix-extract-subrow '(2 2 (1 2 3 4)) 1 0 2)
             '(1 2 (3 4))))
    (should (equal
             (matrix-scalar-product
              (matrix-identity 3)
              7)
             '(3 3 (7 0 0 0 7 0 0 0 7))))))

#+END_SRC
** A system of equations as matrix product
Now that we have all our tools we can write down a matrix product that will mimic our system of equation.

\begin{equation}
\begin{bmatrix}
3 & 2 & 1\\
2 & 3 & 1\\
1 & 2 & 3\\
\end{bmatrix}
\begin{bmatrix}
x\\
y\\
z\\
\end{bmatrix}
=
\begin{bmatrix}
39\\
34\\
26\\
\end{bmatrix}
\end{equation}

Going through our algorithm manually we see that the resulting matrix is:

\begin{equation}
\begin{bmatrix}
3x + 2y + z\\
2x + 3y + z\\
x + 2y + 3z\\
\end{bmatrix}
=
\begin{bmatrix}
39\\
34\\
26\\
\end{bmatrix}
\end{equation}

*** The mirror universe

Now I said that flipped matrix was also a valid representation. We can confirm this by taking the transpose of both sides 


\begin{equation}
\begin{bmatrix}
x & y & z\\
\end{bmatrix}
\begin{bmatrix}
3 & 2 & 1\\
2 & 3 & 2\\
1 & 1 & 3\\
\end{bmatrix}
=
\begin{bmatrix}
39 & 34 & 26\\
\end{bmatrix}
\end{equation}


It yields another matrix product that mimics the equations, however you'll see in the textbook that we always prefer the first notation.

** Chaining problems through matrix composition
The real power of matrix multiplication is in its ability to chain systems together through *linear composition*

If we are given a new problem that take the output of our first system and produces a new output - composition gives us a mechanism to combine the systems into one.

*** Taxing our farmers
Say the imperial palace has a system for collecting taxes
#+BEGIN_QUOTE
*Given*:\\
The farms have to pay a percentage of their income to different regional governements. The breakdown is as follows:\\
The town taxes Farm 1 at 5%, Farm 2 at 3%, Farm 3 at 7%\\
The province taxes all Farm 1 at 2% Farm 2 at 4%, Farm 3 at 2%\\
The palace taxes all farms at 7%
#+END_QUOTE
Now, given the income of each farm *i* we can build a new matrix *B* and calculate the tax revenue of each government - *t*.\\

\begin{equation}
Bi=t
\end{equation}

From the previous problem we know that the income of each farm was already a system of equation with the price of fruit as input *f*\\

\begin{equation}
Af=i
\end{equation}

So we just plug one into the other and get\\
\begin{equation}
B(Af)=t
\end{equation}

and compose a new equation that given the price of fruit gives us the regional tax revenue. By carrying out the product we can generate one linear system\\

\begin{equation}
(BA)f=t\\
\end{equation} 
Where if *BA=C* the final composed system is:
\begin{equation}
Cf=t
\end{equation} 
Note that the rows of *BA* are the combination of the rows of *A* and the columns of *BA* are the combination of the columns of *B* - at the same time! (see page 98)
*** EXAMPLE: Geometrical transformations
A very simple example are the linear systems that takes coordinates /x y/ and do transformations on them

*Rotation*
\begin{equation}
\begin{bmatrix}
\cos \theta & -\sin \theta \\
\sin \theta & \cos \theta \\
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
\end{bmatrix}
=
\begin{bmatrix}
x_{rotated}\\
y_{rotated}\\
\end{bmatrix}
\end{equation}

#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-rotate-2D (radians)
    "Generate a matrix that will rotates a [x y] column vector by RADIANS"
    (matrix-from-data-list
     2
     2
     (list
       (cos radians)
       (- (sin radians))
       (sin radians)
       (cos radians))))
#+END_SRC
*Reflection about X-Axis*
\begin{equation}
\begin{bmatrix}
1 & 0 \\
0 & -1\\
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
\end{bmatrix}
=
\begin{bmatrix}
x_{reflected}\\
y_{reflected}\\
\end{bmatrix}
\end{equation}

#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-reflect-around-x-2D ()
    "Generate a matrix that will reflect a [x y] column vector around the x axis"
    (matrix-from-data-list
     2
     2
     '(1 0 0 -1)))
#+END_SRC
*Projection on line*
\begin{equation}
\begin{bmatrix}
1/2 & 1/2 \\
1/2 & 1/2\\
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
\end{bmatrix}
=
\begin{bmatrix}
x_{projected}\\
y_{projected}\\
\end{bmatrix}
\end{equation}

#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-project-on-x=y-diagonal-2D ()
    "Generate a matrix that projects a point ([x y] column vector) onto a line (defined w/ a unit-vector)"
    (matrix-from-data-list
     2
     2
     '(0.5 0.5 0.5 0.5)))
#+END_SRC
So given a point /[x y]/ (represented by the column vector *v*) we can use these 3 transformation matrices to move it around our 2D space. We simple write a chain of transformations *T* and multiply them times the given vector *T_{1}T_{2}T_{3}v=v_new*. These transformation matrices can then be multiplied together into one that will carry out the transformation in one matrix product. *T_{1}T_{2}T_{3}=T_{total}* => *T_{total}v=v_new* 
* Equivalent matrices
Now thanks to matrix multiplication we can represent linear systems and we can chain them together. The next step is extending multiplication to represent general manipulations of matrices.

** Identity Matrix
For any matrix *A*, the identity matrix *I* is such that *A*I* = *A* = *I*A*. Given the dimensions, *I* has to be a square matrix. It will have *1*'s on the diagonal (ie. where ~row==column~) and zeroes everywhere else. We build it recursively:
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-identity (rank)
    "Build an identity matrix of the given size/rank"

    (defun matrix-build-identity-rec (rank row column)
      "Helper function that build the data vector of the identity matrix"
      (if (equal column rank) ; time to build next row
          (if (equal row (1- rank))
              '() ; we're done
            (matrix-build-identity-rec
             rank
             (1+ row)
             0))
        (if (equal row column)
            (cons
             1
             (matrix-build-identity-rec
              rank
              row
              (1+ column)))
          (cons
           0
           (matrix-build-identity-rec
            rank
            row
            (1+ column))))))
    
    (matrix-from-data-list rank rank (matrix-build-identity-rec rank 0 0 )))
#+END_SRC

** Unit Column/Rows
Each column of the *identity matrix* is a unit column (denoted as *e_{/j/}*). It contains a *1* in a given postion (here: /j/) and *0s* everwhere else. Its transpose is naturally called the *unit row*\\
*Ae_{/j/}* = the /j/ column of A\\
*e_{/i/}^{T}A* = the /i/ row of A\\
*e_{/i/}^{T}Ae_{/j/}* = gets the [ /i/, /j/ ] element in A

#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-unit-rowcol-data (index size)
  "Create a data-list for a matrix row/column. INDEX (starts at ZERO) matches the row or column where you want a 1. SIZE is the overall size of the vector"
  (if (zerop size)
      '()
    (if (zerop index)
        (cons
         1
         (matrix-unit-rowcol-data
          (1- index)
          (1- size)))
      (cons
       0
       (matrix-unit-rowcol-data
        (1- index)
        (1- size))))))
  (defun matrix-unit-column (row size)
    "Build a unit column. ROW is where you want the 1 to be placed (ZERO indexed). SIZE is the overall length"
        (matrix-from-data-list
         size
         1
         (matrix-unit-rowcol-data
          row
          size)))
  (defun matrix-unit-row (column size)
    "Build a unit column. COLUMN is where you want the 1 to be placed (ZERO indexed). SIZE is the overall length"
        (matrix-from-data-list
         1
         size
         (matrix-unit-rowcol-data
          column
          size)))

#+END_SRC
#+BEGIN_QUOTE
Here I'm just trying out a new notation. With ~letrec~ we can hide the recursive helper function inside the function that uses it.
#+END_QUOTE

** Addition
As a tool in building new matrices, we need a way to easily add two matrices, ie. add their values one to one. Matrices that are added need to have the same size.

#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-equal-size-p (matrix1 matrix2)
    "Check if 2 matrices are the same size"
    (and
     (equal
      (matrix-rows matrix1)
      (matrix-rows matrix2))
     (equal
      (matrix-columns matrix1)
      (matrix-columns matrix2))))
  (defun for-each-pair (list1 list2 operator)
    "Go through 2 lists applying an operator on each pair of elements"
    (if (null list1)
        '()
      (cons
       (funcall operator (car list1) (car list2))
       (for-each-pair (cdr list1) (cdr list2) operator))))

  (defun matrix-add (matrix1 matrix2)
    "Add to matrices together"
    (if (matrix-equal-size-p matrix1 matrix2)
        (matrix-from-data-list
         (matrix-rows matrix1)
         (matrix-columns matrix1)
         (for-each-pair
          (matrix-data matrix1)
          (matrix-data matrix2)
          '+))))

  (defun matrix-subtract (matrix1 matrix2)
    "Subtract MATRIX2 from MATRIX1"
    (if (matrix-equal-size-p matrix1 matrix2)
        (matrix-from-data-list
         (matrix-rows matrix1)
         (matrix-columns matrix1)
         (for-each-pair
          (matrix-data matrix1)
          (matrix-data matrix2)
          '-))))
#+END_SRC
#+BEGIN_QUOTE
~funcall~ applied the first arugment (a function) with the remaining items in the list as arguments
#+END_QUOTE
** TESTS :noexport:
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (ert-deftest matrix-test-operations ()
    "Testing - Matrix Operations"
    (let ((matrix1 '(2 2 (1 2 3 4)))
          (matrix2 '(2 2 (5 6 7 8))))
      (should (equal
               (matrix-identity 3)
               '(3 3 (1 0 0 0 1 0 0 0 1))))
      (should (equal
               (matrix-unit-column 3 5)
               '( 5 1 (0 0 0 1 0))))
      (should (equal
               (matrix-equal-size-p matrix1 matrix2)
               't))
      (should (equal
               (matrix-add matrix1 matrix2)
               '(2 2 (6 8 10 12))))
      (should (equal
               (matrix-subtract matrix1 matrix2)
               '(2 2 (-4 -4 -4 -4))))))
#+END_SRC

** Elementary Matrices
The manipulation of the rows and columns can be broken down into 3 types of *elementary matrices* that when multiplied with our *linear systems* will generate *equivalent* matrices (*E*). 

/(from page 134)/
When applied from the /left/ *EA=B* it performs a row operation and makes a *row equivalent* matrix.\\
When applied from the /right/ *AE=B* it performs a column operation and makes a *column equivalent* matrix.\\

Row/column operations are ofcourse reversible and therefore *E* is invertible and a *E^{-1}* always exists.

So now, waving our hands a little, given a non-singular matrix we can restate /Gauss-Jordan elimination/ as "a bunch of row operations that turn our matrix into the identity matrix". Ie: *E_{k}..E_{2}E_{1}A=I*\\
And thanks to each operations' invertibility we can flip it to be *A=E_{1}^{-1}E_{2}^{-1}..E_{k}^{-1}*\\
So Gauss-Jordan elimination for non-singular matrices has given us our first decomposition of sorts! We now know that every non-singular matrix can be written as a chain of row (or column) operations.

Row/Column operations come in 3 flavors
*** Type I - Row/Column Interchange
    Interchaning rows (or columns) /i/ and /j/
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-elementary-interchange (rowcol1 rowcol2 rank)
    "Make an elementary row/column interchange matrix for ROWCOL1 and ROWCOL2 (ZERO indexed)"
    (let ((u
           (matrix-subtract
            (matrix-unit-column rowcol1 rank)
            (matrix-unit-column rowcol2 rank))))
    (matrix-subtract
     (matrix-identity rank)
     (matrix-product
      u
      (matrix-transpose u)))))

  (defun matrix-elementary-interchange-inverse (rowcol1 rowcol2 rank)
    "Make the inverse of the elementary row/column interchange matrix for ROWCOL1 and ROWCOL2 (ZERO indexed). This is identical to (matrix-elementary-interchange)"
    (matrix-elementary-interchange
     rowcol1
     rowcol2
     rank))
#+END_SRC

*** Type II - Row/Column Multiple
Multiplying row (or column) /i/ by /\alpha/
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-elementary-multiply (rowcol scalar rank)
    "Make an elementary row/column multiple matrix for a given ROWCOL (ZERO indexed)"
    (let ((elementary-column
           (matrix-unit-column rowcol rank)))
    (matrix-subtract
     (matrix-identity rank)
     (matrix-product
      elementary-column
      (matrix-scalar-product
       (matrix-transpose elementary-column)
       (- 1 scalar))))))

  (defun matrix-elementary-multiply-inverse (rowcol scalar rank)
    "Make the inverseof the elementary row/column multiple matrix for a given ROWCOL (ZERO indexed)"
    (matrix-elementary-multiply
     rowcol
     (/ 1 scalar)
     rank))
#+END_SRC

*** Type III - Row/Column Addition
Adding a multiple of a row (or column) /i/ to row (or column) /j/
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-elementary-addition (rowcol1 rowcol2 scalar rank)
    "Make an elementary row/column product addition matrix. Multiply ROWCOL1 (ZERO indexed) by SCALAR and add it to ROWCOL2 (ZERO indexed)"
    (matrix-add
     (matrix-identity rank)
     (matrix-scalar-product
      (matrix-product
       (matrix-unit-column rowcol2 rank)
       (matrix-transpose
        (matrix-unit-column rowcol1 rank)))
      scalar)))

  (defun matrix-elementary-addition-inverse (rowcol1 rowcol2 scalar rank)
    "Make the inverse of the elementary row/column product addition matrix. Multiply ROWCOL1 (ZERO indexed) by SCALAR and add it to ROWCOL2 (ZERO indexed)"
    (matrix-elementary-addition
     rowcol1
     rowcol2
     (- scalar)
     rank))
#+END_SRC

** TESTS :noexport:
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (ert-deftest matrix-test-elementary-operation ()
    "Testing - Elementary Matrix Transformations"
    (let ((matrix1 '(2 2 (1 2 3 4)))
          (matrix2 '(2 2 (5 6 7 8))))
      (should (equal
               (matrix-elementary-interchange 0 1 3)
               '(3 3 (0 1 0 1 0 0 0 0 1))))
      (should (equal
               (matrix-elementary-multiply 1 7 3)
               '(3 3 (1 0 0 0 7 0 0 0 1))))
      (should (equal
               (matrix-elementary-addition 0 2 7 3)
               '(3 3 (1 0 0 0 1 0 7 0 1))))))
#+END_SRC

* The LU Decomposition - Gaussian elimination in matrix form
If linear equations at their simplest take inputs and produce some outputs, then Gaussian elimination is our method of reversing the process. It's a systematic way for taking a known linear system with a given output and solving for its input. Because we know that adding and scaling equations preserves equalities, Gaussian elimination is a scheme for combining and swapping equations so that they reduce to something simpler which can be solved directly. We do this by elimination factors in our equations such that the last one is of the form *\alpha{}x=b*. Equalities being preserved, we can use this simple equation to solve for one of the unknown inputs. Each of the remaining equation includes just one additional unknow input so that through back-substitution we can then solve for all of them one by one. 

So if *Ax=b* is our original system of equations in matrix form, then after Gaussian elimination we can write our simplified systm as *Ux=b_{new}*. Combining our equations has changed our output values, so the *b* does not remain the same.


/From the Example on page 141/ \\
So if we started with an *A* that looked like this
\begin{bmatrix}
2 & 2 & 2\\
4 & 7 & 7\\
6 & 18 & 22\\
\end{bmatrix}
Gaussian elimination will give us a *U* that look like this:
\begin{bmatrix}
2 & 2 & 2\\
0 & 3 & 3\\
0 & 0 & 4\\
\end{bmatrix}
Looking at *Ux=b_{new}* we see that the last row in *U* [ 0 0 4 ] times the column [ x_{1} x_{2} x_{3} ]^{T}, given a *b_{new}*, gives us a direct solution for x_{3}. Then using *x_{3}* and the previous row/equation we could solve for *x_{2}* and so on.

Combining and swapping rows is something we just learned how to do using elementary matrices- so by cleverly taking their product with our matrix *A* we will be able to generate the *U* matrix - in effect reenacting Gaussian elimination using matrix multiplication. After that if we want to get our *b_{new}* we will then just repeat those matrix-products with the output vector *b*. If each row manipulation is some elementary matrix *R_{n}* we could write out the process of Gaussian elimination as a series of products *R_{n}R_{...}R_{2}R_{1}A=U*. With the full equation *Ax=b* it's just the same - we can simply multiply by both sides by the *R* matrices *R_{n}R_{...}R_{2}R_{1}(Ax)=R_{1}R_{2}R_{...}R_{n}b*. Here the left side will equal to *Ux* and the right hand side is our *b_{new}*.

On a high level the reduction of the equations happens in two repeated steps on each column: First we adjust the pivot and then we eliminate all the factors below it. In the matrix representation this is equivalent to adjusting the diagonal element and then making all the values below it equal to zero. The combination of the two *reduces the column* and make our system simpler. 

#+BEGIN_QUOTE
*Note:* Gaussian elimination will only produce a solution for nonsingular square matrices, so the process described only holds for this case
#+END_QUOTE
** Elementary Lower Triangular
The example I used above was done without adjusting any pivots. When reducing the first column we simply eliminated the values below the ~2~ (in the upper left) and we could have done that by multiply our *A* by two ~Type III~ *elementary matrices*
\begin{equation}
\begin{bmatrix}
1 & 0 & 0\\
-2 & 1 & 0\\
0 & 0 & 1\\
\end{bmatrix}
\begin{bmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
-3 & 0 & 1\\
\end{bmatrix}
\begin{bmatrix}
2 & 2 & 2\\
4 & 7 & 7\\
6 & 18 & 22\\
\end{bmatrix}
\end{equation}
The two ~Type III~ *elementary matrices* on the left side are pretty simple and you can visually see what the ~-2~ and ~-3~ represent. They match the entry in *A* at the same index (row/column), but divided by the value of the pivot (ie: the factor that will eliminate the value). If you carry out the product you will see the first column has been reduced and we are closer to our upper triangular *U*
\begin{bmatrix}
2 & 2 & 2\\
0 & 3 & 3\\
0 & 12 & 16\\
\end{bmatrix}
Constructing these simple ~Type III~ matrices is quick and inverting them is as easy as flipping the sign on the factor (ie. if you subtract some multiple of an equation from another, to reverse the operation you'd simply add the same multiple of the equation back)
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-elementary-row-elimination (matrix row column)
    "Make a matrix that will eliminate an element at the specified ROW/COLUMN (ZERO indexed) using the diagonal element in the same column (typically the pivot)"
    (let
        ((pivot (matrix-get-value matrix column column))
         (element-to-eliminate (matrix-get-value matrix row column)))
      (matrix-elementary-addition
       column
       row
       (-
        (/
         element-to-eliminate
         pivot))
       (matrix-rows matrix))))

#+END_SRC

Looking again at the product of 2 ~Type III~ matrices with our *A*, and using what we know about composing linear systems, we already know that we can take the product of the first two matrices separately. Whatever matrix comes out of that can then me multiplied times *A* to give us the same result.
\begin{equation}
\begin{pmatrix}
\begin{bmatrix}
1 & 0 & 0\\
-2 & 1 & 0\\
0 & 0 & 1\\
\end{bmatrix}
\begin{bmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
-3 & 0 & 1\\
\end{bmatrix}
\end{pmatrix}
\begin{bmatrix}
2 & 2 & 2\\
4 & 7 & 7\\
6 & 18 & 22\\
\end{bmatrix}
\end{equation}


\begin{equation}
\begin{bmatrix}
1 & 0 & 0\\
-2 & 1 & 0\\
-3 & 0 & 1\\
\end{bmatrix}
\begin{bmatrix}
2 & 2 & 2\\
4 & 7 & 7\\
6 & 18 & 22\\
\end{bmatrix}
\end{equation}

The result is surprisingly simple and we can see that we didn't really need to carry out the whole matrix product b/c we've simply merged the factors into one matrix. So we can simply build these matrices that eliminate entire columns and skip making ~Type III~ matrices entirely. The new combined matrices are called *Elementary Lower-Triangular Matrix* and are described on /page 142/.
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-elementary-lower-triangular (matrix column-to-clear)
    "Make a matrix that will eliminate all rows in a column below the diagonal (pivot position)"

    (defun matrix-elementary-lower-triangular-rec (matrix column-to-clear row-to-build rank)
      "Recursive function to build the elementary lower triangular matrix"
      (cond
       ((equal
         rank
         row-to-build) ; Done building the matrix
        '())
       ((<=
         row-to-build
         column-to-clear) ; Building the simply "identity" portion above the pivot
        (matrix-append
         (matrix-unit-row row-to-build rank)
         (matrix-elementary-lower-triangular-rec
          matrix
          column-to-clear
          (1+ row-to-build)
          rank)))
       (t ; Build the elimination portion below the pivot
        (let
            ((pivot (matrix-get-value matrix column-to-clear column-to-clear))
             (element-to-eliminate (matrix-get-value matrix row-to-build column-to-clear)))
          (let
              ((cancellation-factor (-
                                     (/
                                      element-to-eliminate
                                      pivot))))
            (matrix-append
             (matrix-add
              (matrix-unit-row row-to-build rank)
              (matrix-scalar-product
               (matrix-unit-row column-to-clear rank)
               cancellation-factor))
             (matrix-elementary-lower-triangular-rec
              matrix
              column-to-clear
              (1+ row-to-build)
              rank)))))))

    (matrix-elementary-lower-triangular-rec
     matrix
     column-to-clear
     0
     (matrix-rows matrix)))

#+END_SRC

So now our product of elementary matrices *R_{n}R_{...}R_{2}R_{1}A=U* shortens to something similar *G_{r}G_{...}G_{2}G_{1}A=U*, but where each /Elementary Lower-Triangular Matrix/ *G* takes the place of several *R* matrices.  These *G* matrices also have the property that their inverse is just a matter of flipping the sign of the factors' (you can confirm this by inverting *G=R_{n}R_{...}R_{2}R_{1}* and remembering that *R^{-1}*'s also are ~Type III~ matrices). This allows us to take our equation *G_{1}G_{2}G_{...}G_{n}A=U* and trivially produce the equality *A=G^{-1}_{1}G^{-1}_{2}G^{-1}_{...}G_{n}U* without having to compute a single value. The product *G^{-1}_{1}G^{-1}_{2}G^{-1}_{...}G_{n}* is special and also combines cleanly without the need for any calculation. It combined to form a lower triangular matrix which is repsented by the letter *L*. So we can now write down *A=LU* - from which we get the name of the decomposition.

If in our example we add another matrix to the left to eliminate the second column in *A* and then we were to take its product with our previous /Elementary Lower-Triangular Matrix/ the factors merge into one lower triangular matrix (see /page 143-144/ */eq 3.10.6/* )

\begin{equation}
\begin{pmatrix}
\begin{bmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
0 & -4 & 1\\
\end{bmatrix}
\begin{bmatrix}
1 & 0 & 0\\
-2 & 1 & 0\\
-3 & 0 & 1\\
\end{bmatrix}
\end{pmatrix}
\begin{bmatrix}
2 & 2 & 2\\
4 & 7 & 7\\
6 & 18 & 22\\
\end{bmatrix}
\end{equation}


\begin{equation}
\begin{bmatrix}
1 & 0 & 0\\
-2 & 1 & 0\\
-3 & -4 & 1\\
\end{bmatrix}
\begin{bmatrix}
2 & 2 & 2\\
4 & 7 & 7\\
6 & 18 & 22\\
\end{bmatrix}
\end{equation}

#+BEGIN_QUOTE
*Note* that the factor of ~-4~ was only deduced after doing the reduction of the first column which had given us:

\begin{bmatrix}
2 & 2 & 1\\
0 & 3 & 3\\
0 & 12 & 16\\
\end{bmatrix}

So you can't reduce the second column before you'd reduced the first!
#+END_QUOTE

Allowing us to write out *A=LU*
\begin{equation}
\begin{bmatrix}
2 & 2 & 2\\
4 & 7 & 7\\
6 & 18 & 22\\
\end{bmatrix}
=
\begin{bmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
3 & 4 & 1\\
\end{bmatrix}
\begin{bmatrix}
2 & 2 & 2\\
0 & 3 & 3\\
0 & 0 & 4\\
\end{bmatrix}
\end{equation}


** Partial Pivoting

The previous example showed us how to eliminate columns, but in general before we do elimination we need to adjust the pivot in that column. First we may find that after performing elimination on a previous column we are left with a zero in the current column's pivot position - which makes it impossible to eliminate the factors below it. Secondly, adjusting the pivot can improve our solution's numerical stability. The strategy we're using is called *partial pivoting* and will swap in to the pivot position whichever row has the maximal value for that column. It will ensure that our results have less error and can also be done directly by taking the product of our matrix with a ~Type I~ elementary matrix.

#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-partial-pivot (matrix pivot-column)
      "Adjust the pivot in the PIVOT-COLUMN to be have the maximal magnititude in that column"
      (let ((column-below-pivot (matrix-submatrix
                                 matrix
                                 pivot-column
                                 pivot-column
                                 (matrix-rows matrix)
                                 (1+ pivot-column))))
        (defun find-max-index (data-list max-val max-index current-index)
          (cond
           ((null data-list)
            max-index)
           ((>
             (abs(car data-list))
             max-val)
            (find-max-index
             (cdr data-list)
             (abs(car data-list))
             current-index
             (1+ current-index)))
           (t
            (find-max-index
             (cdr data-list)
             max-val
             max-index
             (1+ current-index)))))

       (matrix-elementary-interchange
        pivot-column
        (+
         pivot-column
         (find-max-index
          (matrix-data column-below-pivot)
          0
          0
          0))
        (matrix-rows matrix))))
#+END_SRC

So if *G_{n}* were the /elementary lower-triangular matrices/ from the last section that performed our eliminations and *F_{n}* are the new *Type I* pivot adjustments, then our reduction need to be rewritten as *G_{1}F_{1}G_{2}F_{2}..G_{r}F_{r}A=U* where each *G* *F* pair corresponds to a reduction of a column: *(G_{1}F_{1})_{col_1}(G_{2}F_{2})_{col_2}..(G_{r}F_{r})_{col_r}A=U*. 

#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-reduce-column (matrix column-to-reduce)
    "Adjusts the pivot using partial pivoting and eliminates the elements in one column. Returns a list of the elimination matrix, permutation matrix and the resulting matrix with reduced column (list of 3 matrices)"
    (let*
        ((pivot-adjusting-matrix
          (matrix-partial-pivot
           matrix
           column-to-reduce) )
         (matrix-with-partial-pivoting
          (matrix-product ; pivot!
           pivot-adjusting-matrix
           matrix))
         (column-elimination-matrix
          (matrix-elementary-lower-triangular
           matrix-with-partial-pivoting
           column-to-reduce))
         (matrix-with-reduced-column
          (matrix-product ; reduce
           column-elimination-matrix
           matrix-with-partial-pivoting)))
      (list column-elimination-matrix pivot-adjusting-matrix matrix-with-reduced-column)))

  (defun matrix-to-upper-triangular (matrix)
    "Take the input MATRIX and use Gaussian elimination to make the upper triangular back-substitution matrix"
    (defun matrix-to-upper-triangular-rec (matrix column-to-reduce)
      (cond
       ((equal
         column-to-reduce
         (matrix-rows matrix))
        matrix)
       (t
        (matrix-to-upper-triangular-rec
         (third (matrix-partial-pivot-and-reduce-column matrix column-to-reduce))
         (1+ column-to-reduce)))))
    (matrix-to-upper-triangular-rec matrix 0))
#+END_SRC

Turning back to our orginal *Ax=b* we can again generate the *b_{new}*: *Ux=(G_{1}F_{1})_{col_1}(G_{2}F_{2})_{col_2}..(G_{r}F_{r})_{col_r}b* -> *Ux=b_{new}*. Then again using back substitution we can get a solution for *x*. However this solution has some flaws. When looking at *(G_{1}F_{1})_{col_1}(G_{2}F_{2})_{col_2}..(G_{r}F_{r})_{col_r}* we can no longer just copy together factors. The result is messy and involves a lot of products and calculations. Before we added the pivots in, we had manage to get a clean equation *A=LU*, but now building that decomposition suddenly isn't possible directly

** Extracting the pivots

On /page 150/ the book shows us how we can fix this situation by extracting the partial pivots out of column reductions so that instead of: *G_{1}F_{1}G_{2}F_{2}..G_{r}F_{r}* we are left with something that looks more like  *G_{1}G_{2}..G_{r}F_{1}F_{2}..F_{r}*. And with the *G*'s together we'd have our *L^{-1}* back. Taking the product of the *F*'s gives us a new /permutation matrix/ *P* so that our final equation will look like *L^{-1}PA = U* or more simply *PA=LU*.Looking at how we extract the pivots from a different perspective - the reason we've had the matrices interleaved is because that's how we build them (from right to left). When looking at an arbitrary column we can't get the right value into its pivot position till we'd carried out all the eliminations in the columns before it. The previous eliminations can potentially change all the values in that column and completely change what row has the maximal value. So the /GFGFGF/ sequence for building the reduction matrices (from right to left, column by column)  needs to be observed. However once we've finished Gaussian elimination then we know the final order of the rows in *U*. And what /page 150/ demonstrates is that if we know the row interchanges, we can actually carry them out first as long as we then fix-up our eliminations matrices a bit. Specifically if you adjust some pivot /k/ by swapping it with row /k+i/ then any /previous/ eliminations that involved the row /k/ (and row /k+i/) now needs to be fixed to reflect that you'll be doing the row interchange ahead of time

The way we go about this programmatically is building our pivot and elimination matrices in the /GFGFGF/ order but each time we get a new pivot matrix *F* we adjust the elimination matrices *G* that we've got so far.

#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-update-elimination-matrix (elementary-lower-triangular-matrix type-i-interchange-matrix)
    "Take an elementary lower triangular matrix and update it to match a row interchange between ROW1 and ROW2 (ZERO indexed)"
      (matrix-product
       type-i-interchange-matrix
       (matrix-product
        elementary-lower-triangular-matrix
        type-i-interchange-matrix)))
#+END_SRC
As you can see here, I'm doing 2 full matrix products while updating a /Elementary Lower Triangular Matrix/ is simply a matter of swapping 2 numbers. The way it's described in the book, you can go and update each column's /Elementary Lower Triangular Matrix/. However in practice it's easier to accumulate elimination matrices into one matrix and to perform the update on the whole accumulation. A more clever solution might keep track of which column is being eliminated and swap the numbers more quickly - but for simplicity I've kept this double-product solution

With our elimination and pivot adjustments separated we again can take the product of our *G*'s together to get *L^{-1}*. Taking the product of the *F*'s gives us a new /permutation matrix/ *P* so that our final equation will look like *L^{-1}PA = U*. Again moving the eliminations to the other side we get a decomposition of sorts *PA=LU*

The gaussian elimination function will return a list of these three matrixes (*L^{-1}* *P* *U*). At each iteration it will pivot and eliminate a column, adjust the elimination matrix that's been built so far, and then multiply-in the new *G* and *F* that it's just built in to the elimination and permutation matrices.
#+BEGIN_SRC emacs-lisp :results output silent :session :tangle matrix.el
  (defun matrix-gaussian-elimination-with-partial-pivoting (matrix)
    "Perform Gaussian elimination with partial pivoting on MATRIX and return the list (L^-1 P U) "
    (let
        ((rank
          (matrix-rows matrix)))
      (defun matrix-gaussian-elimination-with-partial-pivoting-rec (elimination-matrix
                                                                    permutation-matrix
                                                                    reduced-matrix
                                                                    column-to-reduce)
        (cond
         ((equal
           column-to-reduce
           rank)
          (list elimination-matrix permutation-matrix reduced-matrix))
         (t
          (let
              ((current-column-reduction-matrices
                (matrix-reduce-column
                 reduced-matrix
                 column-to-reduce)))
            (matrix-gaussian-elimination-with-partial-pivoting-rec
             (matrix-product
              (first current-column-reduction-matrices)
              (matrix-update-elimination-matrix       ; update elimination matrices due to partial pivot
               elimination-matrix
               (second current-column-reduction-matrices)))
             (matrix-product                              ; update the permutation matrix
              (second current-column-reduction-matrices)
              permutation-matrix)
             (third current-column-reduction-matrices)    ; the further reduced matrix
             (1+ column-to-reduce))))))

      (matrix-gaussian-elimination-with-partial-pivoting-rec
       (matrix-identity rank)
       (matrix-identity rank)
       matrix
       0)))
#+END_SRC





* TODOs
Write a better example that I can expand on easily later
Write an algo for /Gauss-Jordan elimination/

* End
#+BEGIN_QUOTE
This webpage is generated from an org-document (at ~./index.org~) that also generates all the files described. 

Once opened in Emacs:\\
- ~C-c C-e h h~ generates the webpage  \\
- ~C-c C-v C-t~ exports the code blocks into the appropriate files\\
#+END_QUOTE
